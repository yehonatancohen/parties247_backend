import os
import json
import logging
import hmac
import re
import copy
import html
from typing import Iterable
from datetime import datetime, timedelta, timezone
from email.utils import format_datetime
from functools import wraps
from urllib.parse import urlparse, urlunparse, parse_qsl, urlencode, quote_plus, urljoin, ParseResult
try:
    from pymongo import UpdateOne
except Exception:  # pragma: no cover - used only when pymongo isn't available in tests
    class UpdateOne:  # minimal stub for tests
        def __init__(self, *args, **kwargs):
            self._args = args
            self._kwargs = kwargs
import socket
import ipaddress

import bcrypt
import jwt
from dotenv import load_dotenv
from flask import Flask, request, jsonify, url_for
from flask_cors import CORS
from flask_limiter import Limiter
from flask_limiter.util import get_remote_address
from pymongo import MongoClient, errors
from pymongo.collection import Collection
from bson.objectid import ObjectId
import requests
from bs4 import BeautifulSoup
from pydantic import BaseModel, ValidationError
from flask_apscheduler import APScheduler

# --- App setup ---
load_dotenv()
app = Flask(__name__)
app.config["RATELIMIT_HEADERS_ENABLED"] = True
app.config["SCHEDULER_API_ENABLED"] = True
CORS(app)
limiter = Limiter(get_remote_address, app=app)
scheduler = APScheduler()
scheduler.init_app(app)
scheduler.start()
logging.basicConfig(level=logging.INFO)

CANONICAL_BASE_URL = (os.environ.get("CANONICAL_BASE_URL") or "https://parties247-website.vercel.app").rstrip("/")
INDEXNOW_KEY = os.environ.get("INDEXNOW_KEY")
INDEXNOW_ENDPOINT = os.environ.get("INDEXNOW_ENDPOINT", "https://api.indexnow.org/indexnow")
INDEXNOW_KEY_LOCATION = os.environ.get("INDEXNOW_KEY_LOCATION")
REVALIDATE_ENDPOINT = os.environ.get("REVALIDATE_ENDPOINT")
REVALIDATE_SECRET = os.environ.get("REVALIDATE_SECRET")

EVENT_CACHE_SECONDS = 1800
LIST_CACHE_SECONDS = 600
FEED_CACHE_SECONDS = 900
ICS_CACHE_SECONDS = 3600
SITEMAP_CACHE_SECONDS = 900
EVENT_SITEMAP_CHUNK = 500

# --- URL canonicalization ---
TRACKING_PREFIXES = ("utm_",)
TRACKING_KEYS = {"fbclid", "gclid", "mc_cid", "mc_eid"}

REFERRAL_KEY = "referral"

GO_OUT_BASE_URL = "https://www.go-out.co"
GO_OUT_EVENT_BASE = f"{GO_OUT_BASE_URL}/event/"
GO_OUT_TICKETS_API_PATH = "/endOne/getEventsByTypeNew"
GO_OUT_TICKETS_PREFIX = "/tickets/"
ISRAEL_TIMEZONE = timezone(timedelta(hours=3), name="Israel Daylight Time")

CANONICAL_PATTERNS = {
    "event": "/event/{slug}",
    "city": "/city/{slug}",
    "venue": "/venue/{slug}",
    "genre": "/genre/{slug}",
    "date": "/date/{slug}",
    "events_feed": "/feeds/events.{fmt}",
    "scoped_feed": "/feeds/{slug}.{fmt}",
    "events_ics": "/ics/event/{slug}.ics",
    "city_ics": "/ics/city/{slug}.ics",
    "sitemap_index": "/sitemap.xml",
    "sitemap_child": "/sitemaps/{name}",
}


def build_canonical(kind: str, **params) -> str:
    """Return an absolute canonical URL based on the configured host."""
    pattern = CANONICAL_PATTERNS.get(kind)
    if not pattern:
        raise KeyError(f"Unsupported canonical kind: {kind}")
    path = pattern.format(**params)
    if not path.startswith("/"):
        path = "/" + path
    return f"{CANONICAL_BASE_URL}{path}"


def absolute_url(path: str) -> str:
    """Build an absolute URL from an absolute or relative path."""
    if not path:
        return CANONICAL_BASE_URL
    if path.startswith("http://") or path.startswith("https://"):
        return path
    if not path.startswith("/"):
        path = "/" + path
    return f"{CANONICAL_BASE_URL}{path}"


def slugify_value(value: str | None) -> str | None:
    if not value:
        return None
    slug = re.sub(r"[^0-9a-zA-Z]+", "-", value.lower()).strip("-")
    return slug or None


def parse_datetime(value) -> datetime | None:
    if not value:
        return None
    if isinstance(value, datetime):
        if value.tzinfo is None:
            return value.replace(tzinfo=timezone.utc)
        return value.astimezone(timezone.utc)
    if isinstance(value, (int, float)):
        return datetime.fromtimestamp(value, tz=timezone.utc)
    if isinstance(value, str):
        text = value.strip()
        if not text:
            return None
        try:
            if text.endswith("Z"):
                return datetime.fromisoformat(text[:-1]).replace(tzinfo=timezone.utc)
            dt = datetime.fromisoformat(text)
            if dt.tzinfo is None:
                return dt.replace(tzinfo=timezone.utc)
            return dt.astimezone(timezone.utc)
        except ValueError:
            pass
        for fmt in ("%Y-%m-%d %H:%M:%S", "%Y-%m-%d"):
            try:
                dt = datetime.strptime(text, fmt)
                if fmt == "%Y-%m-%d":
                    return datetime(dt.year, dt.month, dt.day, tzinfo=timezone.utc)
                return dt.replace(tzinfo=timezone.utc)
            except ValueError:
                continue
    return None


def isoformat_or_none(value) -> str | None:
    dt = parse_datetime(value)
    if not dt:
        return None
    return dt.astimezone(timezone.utc).isoformat().replace("+00:00", "Z")


def extract_bilingual(source: dict, base_key: str, fallback: str | None = None) -> dict:
    he_keys = [f"{base_key}He", f"{base_key}_he", f"{base_key}_hebrew"]
    en_keys = [f"{base_key}En", f"{base_key}_en", f"{base_key}_english"]
    he_val = None
    en_val = None
    for key in he_keys:
        if key in source and source[key]:
            he_val = source[key]
            break
    for key in en_keys:
        if key in source and source[key]:
            en_val = source[key]
            break
    base_val = source.get(base_key)
    if isinstance(base_val, dict):
        he_val = he_val or base_val.get("he")
        en_val = en_val or base_val.get("en")
    elif isinstance(base_val, str):
        he_val = he_val or base_val
        en_val = en_val or base_val
    he_val = he_val or fallback or ""
    en_val = en_val or fallback or ""
    return {"he": he_val, "en": en_val}


def extract_geo(doc: dict) -> dict:
    geo = doc.get("geo") or {}
    if isinstance(geo, dict):
        lat = geo.get("lat") or geo.get("latitude")
        lon = geo.get("lon") or geo.get("lng") or geo.get("longitude")
        address = geo.get("address") or geo.get("street")
        postal = geo.get("postalCode") or geo.get("zip")
    else:
        lat = lon = address = postal = None
    lat = lat if isinstance(lat, (int, float)) else doc.get("lat") or doc.get("latitude")
    lon = lon if isinstance(lon, (int, float)) else doc.get("lon") or doc.get("longitude")
    address = address or doc.get("address") or doc.get("location")
    postal = postal or doc.get("postalCode")
    result = {
        "lat": float(lat) if isinstance(lat, (int, float, str)) and str(lat).strip() else None,
        "lon": float(lon) if isinstance(lon, (int, float, str)) and str(lon).strip() else None,
        "address": address or "",
        "postalCode": postal or "",
    }
    return result


def derive_status(doc: dict) -> str:
    status = (doc.get("status") or "").lower()
    allowed = {"scheduled", "cancelled", "postponed", "past"}
    if status in allowed:
        return status
    start = parse_datetime(doc.get("startsAt") or doc.get("date"))
    now = datetime.utcnow().replace(tzinfo=timezone.utc)
    if start and start < now:
        return "past"
    return "scheduled"

def normalize_url(raw: str) -> str:
    p = urlparse((raw or "").strip())
    scheme = (p.scheme or "https").lower()
    netloc = p.netloc.lower()
    if netloc.endswith(":80") and scheme == "http":
        netloc = netloc[:-3]
    if netloc.endswith(":443") and scheme == "https":
        netloc = netloc[:-4]
    path = p.path.rstrip("/") or "/"
    cleaned_qs = []
    for k, v in parse_qsl(p.query, keep_blank_values=True):
        kl = k.lower()
        if kl.startswith(TRACKING_PREFIXES) or kl in TRACKING_KEYS:
            continue
        cleaned_qs.append((k, v))
    query = urlencode(cleaned_qs, doseq=True)
    return urlunparse((scheme, netloc, path, "", query, ""))

def normalized_or_none_for_dedupe(raw: str) -> str | None:
    n = normalize_url(raw)
    return n if urlparse(n).netloc else None


def _append_query_param(url: str | None, key: str, value: str | None) -> str | None:
    if not url or not value:
        return url
    try:
        parsed = urlparse(url)
    except Exception:
        return url
    if not parsed.netloc:
        return url
    query_items = parse_qsl(parsed.query, keep_blank_values=True)
    key_lower = key.lower()
    if any(k.lower() == key_lower for k, _ in query_items):
        return urlunparse(parsed)
    query_items.append((key, value))
    new_query = urlencode(query_items, doseq=True)
    return urlunparse(parsed._replace(query=new_query))


def append_referral_param(url: str | None, referral: str | None) -> str | None:
    """Append the referral query parameter to the URL when missing."""
    return _append_query_param(url, "ref", referral)


def append_affiliate_param(url: str | None, referral: str | None) -> str | None:
    """Append the Go-Out affiliate parameter if a referral code exists."""
    return _append_query_param(url, "aff", referral)


def default_referral_code() -> str | None:
    """Fetch the default referral code from the settings collection."""
    if settings_collection is None:
        return None
    try:
        doc = settings_collection.find_one({"key": REFERRAL_KEY}) or {}
    except Exception as exc:
        app.logger.warning(f"Failed to fetch referral code: {exc}")
        return None
    value = (doc.get("value") or "").strip()
    return value or None


def apply_default_referral(party: dict, referral: str | None) -> None:
    """Mutate the party dict to ensure URLs carry the referral code."""
    if not party or not referral:
        return
    for key in ("goOutUrl", "originalUrl"):
        if key in party:
            party[key] = append_referral_param(party.get(key), referral)
    if not party.get("referralCode"):
        party["referralCode"] = referral

ALLOWED_SCHEMES = {"http", "https"}
ALLOWED_PORTS = {80, 443}

def is_url_allowed(raw: str) -> bool:
    try:
        parsed = urlparse(raw)
    except Exception:
        return False
    if parsed.scheme.lower() not in ALLOWED_SCHEMES:
        return False
    if parsed.port and parsed.port not in ALLOWED_PORTS:
        return False
    host = parsed.hostname
    if not host:
        return False
    try:
        infos = socket.getaddrinfo(host, parsed.port or (80 if parsed.scheme == "http" else 443))
    except socket.gaierror:
        return False
    for info in infos:
        ip = ipaddress.ip_address(info[4][0])
        if ip.is_private or ip.is_loopback or ip.is_reserved or ip.is_link_local or ip.is_multicast:
            return False
    return True


def json_response(payload, status: int = 200, cache_seconds: int | None = None, robots: str | None = "noindex"):
    headers = {
        "Content-Type": "application/json",
    }
    if cache_seconds is not None:
        headers["Cache-Control"] = f"public, max-age={cache_seconds}"
    if robots:
        headers["X-Robots-Tag"] = robots
    return jsonify(payload), status, headers


def text_response(body: str, content_type: str, cache_seconds: int | None = None, robots: str | None = None, status: int = 200):
    headers = {"Content-Type": content_type}
    if cache_seconds is not None:
        headers["Cache-Control"] = f"public, max-age={cache_seconds}"
    if robots:
        headers["X-Robots-Tag"] = robots
    return body, status, headers

# --- Mongo helpers ---
def ensure_index(coll: Collection, keys, name: str, **kwargs):
    info = coll.index_information()
    if name in info:
        meta = info[name]
        same_keys = meta.get("key") == list(keys)
        same_unique = bool(meta.get("unique", False)) == bool(kwargs.get("unique", False))
        same_pfe = meta.get("partialFilterExpression") == kwargs.get("partialFilterExpression")
        if same_keys and same_unique and same_pfe:
            return
        try:
            coll.drop_index(name)
        except Exception as e:
            app.logger.warning(f"Drop index {name} failed: {e}")
    coll.create_index(list(keys), name=name, **kwargs)

# --- Mongo connection + index hygiene ---
try:
    client = MongoClient(os.environ.get("MONGODB_URI"))
    db = client["party247"]
    parties_collection: Collection = db.parties
    carousels_collection: Collection = db.carousels
    sections_collection: Collection = db.sections
    tags_collection: Collection = db.tags
    settings_collection: Collection = db.settings
    party_analytics_collection: Collection = db.partyAnalytics
    visitor_analytics_collection: Collection = db.analyticsVisitors
    analytics_collection: Collection = db.analytics

    try:
        parties_collection.update_many(
            {"$or": [{"goOutUrl": None}, {"goOutUrl": ""}]},
            {"$unset": {"goOutUrl": ""}}
        )
    except Exception as e:
        app.logger.warning(f"goOutUrl cleanup failed: {e}")

    try:
        for name, meta in parties_collection.index_information().items():
            if meta.get("unique") and meta.get("key") == [("originalUrl", 1)]:
                parties_collection.drop_index(name)
                app.logger.info(f"Dropped legacy unique index on originalUrl: {name}")
    except Exception as e:
        app.logger.warning(f"Drop originalUrl index failed: {e}")

    try:
        for name, meta in parties_collection.index_information().items():
            if meta.get("key") == [("goOutUrl", 1)]:
                parties_collection.drop_index(name)
                app.logger.info(f"Dropped legacy index on goOutUrl: {name}")
    except Exception as e:
        app.logger.warning(f"Drop goOutUrl index failed: {e}")

    ensure_index(
        parties_collection,
        [("canonicalUrl", 1)],
        name="unique_canonicalUrl",
        unique=True,
        partialFilterExpression={"canonicalUrl": {"$exists": True, "$type": "string"}}
    )
    ensure_index(
        parties_collection,
        [("goOutUrl", 1)],
        name="unique_goOutUrl",
        unique=True,
        partialFilterExpression={"goOutUrl": {"$exists": True, "$type": "string"}}
    )
    ensure_index(parties_collection, [("date", 1)], name="date_asc")

    ensure_index(carousels_collection, [("title", 1)], name="title_asc")
    ensure_index(carousels_collection, [("order", 1)], name="carousel_order_asc")

    ensure_index(tags_collection, [("slug", 1)], name="unique_slug", unique=True)
    ensure_index(tags_collection, [("order", 1)], name="tag_order_asc")

    ensure_index(settings_collection, [("key", 1)], name="unique_key", unique=True)
    ensure_index(party_analytics_collection, [("partyId", 1)], name="unique_party", unique=True)
    ensure_index(visitor_analytics_collection, [("sessionId", 1)], name="unique_session", unique=True)
    ensure_index(analytics_collection, [("category", 1), ("action", 1)], name="category_action")
    ensure_index(
        visitor_analytics_collection,
        [("createdAt", 1)],
        name="visitor_created_ttl",
        expireAfterSeconds=172800,
    )

    app.logger.info("Connected to MongoDB and ensured indexes.")
except Exception as e:
    app.logger.error(f"Error connecting to MongoDB Atlas: {e}")
    parties_collection = None
    carousels_collection = None
    sections_collection = None
    tags_collection = None
    settings_collection = None
    party_analytics_collection = None
    visitor_analytics_collection = None
    analytics_collection = None


def record_setting_hit(key: str, extra: dict | None = None):
    if settings_collection is None:
        return
    payload = {"key": key, "lastHit": datetime.utcnow()}
    if extra:
        payload.update(extra)
    try:
        settings_collection.update_one({"key": key}, {"$set": payload}, upsert=True)
    except Exception as exc:  # pragma: no cover - best effort only
        app.logger.warning(f"Failed to persist analytics hit {key}: {exc}")


ANALYTICS_TEXT_LIMIT = 256


def sanitize_analytics_text(value: str | None) -> str | None:
    if not value:
        return None
    text = str(value).strip()
    if not text:
        return None
    return text[:ANALYTICS_TEXT_LIMIT]


def extract_client_ip(flask_request) -> str | None:
    candidates = [
        flask_request.headers.get("X-Forwarded-For"),
        flask_request.headers.get("CF-Connecting-IP"),
        flask_request.headers.get("X-Real-IP"),
    ]
    for candidate in candidates:
        if not candidate:
            continue
        ip = candidate.split(",")[0].strip()
        if ip:
            return ip
    return getattr(flask_request, "remote_addr", None)


def is_party_live(party: dict, now: datetime | None = None) -> bool:
    """Return True when the party occurs within the live window."""
    now = now or datetime.now(timezone.utc)
    cutoff = now - timedelta(days=1)
    for key in ("date", "startsAt", "endsAt"):
        value = party.get(key)
        dt = parse_datetime(value)
        if dt:
            return dt >= cutoff
    return True


def fetch_all_documents(coll: Collection | None) -> list[dict]:
    if coll is None:
        return []
    try:
        cursor = coll.find({})
    except TypeError:  # pragma: no cover - compatibility with simple stubs
        cursor = coll.find()
    except Exception as exc:  # pragma: no cover - defensive; surfaced to caller
        app.logger.error(f"Failed to read documents from collection: {exc}")
        raise
    if cursor is None:
        return []
    if isinstance(cursor, list):
        return list(cursor)
    try:
        return list(cursor)
    except TypeError:  # pragma: no cover - fallback for cursors missing __iter__
        return []


def find_party_for_analytics(party_id: str | None, party_slug: str | None) -> dict | None:
    if parties_collection is None:
        return None
    queries = []
    if party_id:
        try:
            queries.append({"_id": ObjectId(party_id)})
        except Exception:
            pass
        queries.append({"_id": party_id})
    if party_slug:
        queries.append({"slug": party_slug})
    seen: set[tuple] = set()
    for query in queries:
        key = tuple(sorted(query.items()))
        if key in seen:
            continue
        seen.add(key)
        try:
            doc = parties_collection.find_one(query)
        except TypeError:  # pragma: no cover - compatibility with tests
            doc = None
        except Exception as exc:
            app.logger.warning(f"Failed to lookup party for analytics: {exc}")
            doc = None
        if doc:
            return doc
    if not queries:
        return None
    for doc in fetch_all_documents(parties_collection):
        if not isinstance(doc, dict):
            continue
        identifier = doc.get("_id")
        if party_id and identifier is not None and str(identifier) == party_id:
            return doc
        if party_slug and sanitize_analytics_text(doc.get("slug")) == sanitize_analytics_text(party_slug):
            return doc
    return None


def build_analytics_summary(window_hours: int = 24) -> dict:
    if (
        party_analytics_collection is None
        or visitor_analytics_collection is None
        or parties_collection is None
    ):
        raise RuntimeError("Analytics datastore unavailable")

    now = datetime.now(timezone.utc)
    visitor_cutoff = now - timedelta(hours=window_hours)

    try:
        try:
            visitor_docs = list(visitor_analytics_collection.find({"createdAt": {"$gte": visitor_cutoff}}))
        except TypeError:  # pragma: no cover - compatibility with tests
            visitor_docs = list(visitor_analytics_collection.find())
    except Exception as exc:
        app.logger.error(f"Failed to read visitor analytics: {exc}")
        raise

    unique_visitors = 0
    for doc in visitor_docs:
        created_at = parse_datetime(doc.get("createdAt"))
        if created_at and created_at >= visitor_cutoff:
            unique_visitors += 1

    try:
        analytics_docs = fetch_all_documents(party_analytics_collection)
    except Exception:
        raise

    metrics_by_party: dict[str, dict] = {}
    for doc in analytics_docs:
        identifier = doc.get("partyId")
        if identifier is None:
            continue
        metrics_by_party[str(identifier)] = doc

    live_parties: list[dict] = []
    live_ids: set[str] = set()
    for party in fetch_all_documents(parties_collection):
        if not isinstance(party, dict):
            continue
        party_identifier = party.get("_id")
        if party_identifier is None:
            continue
        party_id = str(party_identifier)
        if not is_party_live(party, now=now):
            if party_id in metrics_by_party:
                try:
                    party_analytics_collection.delete_one({"partyId": party_id})
                except Exception:  # pragma: no cover - best effort cleanup
                    pass
            continue
        live_ids.add(party_id)
        metrics = metrics_by_party.get(party_id, {})
        live_parties.append(
            {
                "partyId": party_id,
                "slug": sanitize_analytics_text(party.get("slug")),
                "name": sanitize_analytics_text(party.get("name")),
                "date": isoformat_or_none(party.get("date") or party.get("startsAt")),
                "views": int(metrics.get("views", 0) or 0),
                "redirects": int(metrics.get("redirects", 0) or 0),
            }
        )

    for doc in analytics_docs:
        identifier = doc.get("partyId")
        if identifier is None:
            continue
        party_id = str(identifier)
        if party_id in live_ids:
            continue
        try:
            party_analytics_collection.delete_one({"partyId": party_id})
        except Exception:  # pragma: no cover - best effort cleanup
            pass

    live_parties.sort(
        key=lambda item: (
            item.get("date") or "",
            item.get("name") or "",
            item.get("partyId"),
        )
    )

    # --- Traffic source breakdown ---
    source_counts = {}
    device_counts = {}
    for doc in visitor_docs:
        created_at = parse_datetime(doc.get("createdAt"))
        if not (created_at and created_at >= visitor_cutoff):
            continue
        source = doc.get("trafficSource") or _parse_referrer_source(doc.get("referer"), (doc.get("utm") or {}).get("source"))
        source_counts[source] = source_counts.get(source, 0) + 1
        device = doc.get("deviceType") or _parse_device_type(doc.get("userAgent"))
        device_counts[device] = device_counts.get(device, 0) + 1

    def to_breakdown_list(d):
        total = sum(d.values()) or 1
        items = sorted(d.items(), key=lambda x: x[1], reverse=True)
        return [{"label": k, "count": v, "percent": round(v / total * 100, 1)} for k, v in items]

    summary = {
        "generatedAt": now.astimezone(timezone.utc).isoformat().replace("+00:00", "Z"),
        "uniqueVisitors24h": int(unique_visitors),
        "parties": live_parties,
        "trafficSources": to_breakdown_list(source_counts),
        "devices": to_breakdown_list(device_counts),
    }
    return summary


def build_time_series_analytics(start: datetime, end: datetime, interval: str = "day", party_slug: str | None = None) -> list[dict]:
    """
    Build time-series analytics for visits, party views, and purchases.
    
    Args:
        start: Start datetime (timezone-aware)
        end: End datetime (timezone-aware)
        interval: Aggregation granularity ("hour" or "day")
        party_slug: Optional party slug to filter metrics
    
    Returns:
        List of time buckets with metrics
    """
    if visitor_analytics_collection is None or analytics_collection is None:
        raise RuntimeError("Analytics datastore unavailable")
    
    # Query visitor analytics for unique sessions (Visits)
    visitor_query = {"createdAt": {"$gte": start, "$lte": end}}
    try:
        visitor_docs = list(visitor_analytics_collection.find(visitor_query))
    except Exception as exc:
        app.logger.error(f"Failed to read visitor analytics: {exc}")
        raise

    # Query analytics events for party views and purchases
    # We look for category="party" and action IN ["view", "redirect"]
    party_event_query = {
        "createdAt": {"$gte": start, "$lte": end},
        "category": "party",
        "action": {"$in": ["view", "redirect"]}
    }
    
    try:
        party_events = list(analytics_collection.find(party_event_query))
    except Exception as exc:
        app.logger.error(f"Failed to read analytics events: {exc}")
        raise

    # Resolve filtering if party_slug is provided
    target_ids = set()
    if party_slug:
        # User input might be an ID or a Slug. We accept both by resolving loosely.
        # We also look up the party to get its canonical ID and Slug to be safe.
        p = find_party_for_analytics(party_slug, party_slug)
        if p:
            if p.get("_id"):
                target_ids.add(str(p["_id"]))
            if p.get("slug"):
                target_ids.add(p.get("slug"))
        # Also add the raw input just in case analytics were logged with raw input before resolution
        target_ids.add(party_slug)

    buckets = {}
    
    # helper to get bucket key
    def get_key(dt):
        if interval == "hour":
            return dt.strftime("%Y-%m-%dT%H:00:00Z")
        return dt.strftime("%Y-%m-%d")

    # 1. Process visits
    for doc in visitor_docs:
        created_at = parse_datetime(doc.get("createdAt"))
        if not created_at:
            continue
        key = get_key(created_at)
        
        if key not in buckets:
            buckets[key] = {
                "timestamp": key,
                "visits": set(),
                "partyViews": 0,
                "purchases": 0
            }
        
        session_id = doc.get("sessionId")
        if session_id:
            buckets[key]["visits"].add(session_id)
            
    # 2. Process party events
    for doc in party_events:
        # Filter if needed
        if target_ids:
            # Match either partyId or label (slug)
            doc_id = doc.get("partyId")
            doc_label = doc.get("label")
            matched = False
            if doc_id and str(doc_id) in target_ids:
                matched = True
            elif doc_label and doc_label in target_ids:
                matched = True
            
            if not matched:
                continue
        
        created_at = parse_datetime(doc.get("createdAt"))
        if not created_at:
            continue
            
        key = get_key(created_at)
        if key not in buckets:
            buckets[key] = {
                "timestamp": key,
                "visits": set(),
                "partyViews": 0,
                "purchases": 0
            }
            
        action = doc.get("action")
        if action == "view":
            buckets[key]["partyViews"] += 1
        elif action == "redirect":
            buckets[key]["purchases"] += 1

    # Convert sets to counts
    results = []
    for key, data in buckets.items():
        data["visits"] = len(data["visits"])
        results.append(data)
        
    results.sort(key=lambda x: x["timestamp"])
    return results


def all_events() -> list[dict]:
    if parties_collection is None:
        return []
    try:
        docs = list(parties_collection.find())
    except TypeError:  # pragma: no cover - compatibility with simple stubs
        docs = list(parties_collection.find({}))
    except Exception as exc:
        app.logger.error(f"Failed to fetch events: {exc}")
        return []
    for doc in docs:
        if "_id" in doc:
            doc["_id"] = str(doc["_id"])
    return docs


def normalize_event(doc: dict) -> dict:
    title = extract_bilingual(doc, "name", fallback=doc.get("title"))
    slug_source = doc.get("name") or doc.get("title")
    if isinstance(slug_source, dict):
        slug_source = slug_source.get("en") or slug_source.get("he")

    slug_override = doc.get("slugOverride")
    slug = slugify_value(
        slug_override or slug_source or title.get("en") or title.get("he")
    )
    if not slug:
        slug = (
            slug_override
            or doc.get("slug")
            or doc.get("slug_en")
            or doc.get("slug_he")
            or slugify_value(doc.get("canonicalUrl"))
        )
    description = extract_bilingual(doc, "description")
    summary = extract_bilingual(doc, "summary", fallback=description.get("en") or description.get("he"))
    starts_at = isoformat_or_none(doc.get("startsAt") or doc.get("date"))
    ends_at = isoformat_or_none(doc.get("endsAt") or doc.get("endDate"))
    lastmod_candidates = [
        doc.get("updatedAt"),
        doc.get("modifiedAt"),
        doc.get("lastModified"),
        doc.get("lastmod"),
        doc.get("createdAt"),
        doc.get("date"),
    ]
    lastmod = None
    for candidate in lastmod_candidates:
        lastmod = isoformat_or_none(candidate)
        if lastmod:
            break
    geo = extract_geo(doc)

    city_raw = doc.get("city") or {}
    if isinstance(city_raw, str):
        city_name = city_raw
        city_slug = slugify_value(city_raw)
        city_geo = geo
    elif isinstance(city_raw, dict):
        city_name = city_raw.get("name") or city_raw.get("title") or ""
        city_slug = city_raw.get("slug") or slugify_value(city_name)
        city_geo = extract_geo(city_raw)
    else:
        city_name = ""
        city_slug = None
        city_geo = {"lat": None, "lon": None, "address": "", "postalCode": ""}
    city = {
        "slug": city_slug or "",
        "name": extract_bilingual(city_raw if isinstance(city_raw, dict) else {}, "name", fallback=city_name),
        "geo": city_geo,
        "canonicalUrl": build_canonical("city", slug=city_slug or ""),
    }

    venue_raw = doc.get("venue") or {}
    if isinstance(venue_raw, str):
        venue_name = venue_raw
        venue_slug = slugify_value(venue_raw)
        venue_geo = geo
    elif isinstance(venue_raw, dict):
        venue_name = venue_raw.get("name") or venue_raw.get("title") or ""
        venue_slug = venue_raw.get("slug") or slugify_value(venue_name)
        venue_geo = extract_geo(venue_raw)
    else:
        venue_name = ""
        venue_slug = None
        venue_geo = {"lat": None, "lon": None, "address": "", "postalCode": ""}
    venue = {
        "slug": venue_slug or "",
        "name": extract_bilingual(venue_raw if isinstance(venue_raw, dict) else {}, "name", fallback=venue_name),
        "geo": venue_geo,
        "canonicalUrl": build_canonical("venue", slug=venue_slug or ""),
    }

    genres = []
    raw_genres = doc.get("genres") or []
    if isinstance(raw_genres, str):
        raw_genres = [raw_genres]
    for item in raw_genres:
        if isinstance(item, dict):
            name = item.get("name") or item.get("title") or ""
            slug_val = item.get("slug") or slugify_value(name)
            genres.append({
                "slug": slug_val or "",
                "name": extract_bilingual(item, "name", fallback=name),
                "canonicalUrl": build_canonical("genre", slug=slug_val or ""),
            })
        elif isinstance(item, str):
            slug_val = slugify_value(item)
            genres.append({
                "slug": slug_val or "",
                "name": {"he": item, "en": item},
                "canonicalUrl": build_canonical("genre", slug=slug_val or ""),
            })

    event_status = derive_status(doc)
    canonical_url = build_canonical("event", slug=slug or "")
    images = doc.get("images") or []
    if isinstance(images, str):
        images = [images]

    return {
        "slug": slug or "",
        "status": event_status,
        "title": title,
        "summary": summary,
        "description": description,
        "canonicalUrl": canonical_url,
        "lastmod": lastmod,
        "startsAt": starts_at,
        "endsAt": ends_at,
        "geo": geo,
        "city": city,
        "venue": venue,
        "genres": genres,
        "images": images,
        "language": doc.get("language") or {"primary": "he", "available": ["he", "en"]},
    }


def upcoming_events(events: list[dict]) -> list[dict]:
    now = datetime.utcnow().replace(tzinfo=timezone.utc)
    upcoming = []
    for event in events:
        status = derive_status(event)
        start = parse_datetime(event.get("startsAt") or event.get("date"))
        if status == "past":
            continue
        if start and start < now:
            continue
        upcoming.append(event)
    return upcoming


def aggregate_dimension(events: list[dict], key: str) -> list[dict]:
    aggregates: dict[str, dict] = {}
    for event in events:
        resource = event.get(key) or {}
        if not isinstance(resource, dict):
            continue
        slug = resource.get("slug") or ""
        if not slug:
            continue
        entry = aggregates.setdefault(slug, {
            "slug": slug,
            "name": resource.get("name", {"he": "", "en": ""}),
            "geo": resource.get("geo", {"lat": None, "lon": None, "address": "", "postalCode": ""}),
            "lastmod": event.get("lastmod"),
            "eventCount": 0,
        })
        entry["eventCount"] += 1
        if event.get("lastmod"):
            if not entry.get("lastmod") or event["lastmod"] > entry["lastmod"]:
                entry["lastmod"] = event["lastmod"]
    result = []
    for slug, payload in aggregates.items():
        payload["canonicalUrl"] = build_canonical(key[:-1] if key.endswith("s") else key, slug=slug)
        result.append(payload)
    result.sort(key=lambda item: item["slug"])
    return result


def serialize_events(include_past: bool = True) -> list[dict]:
    docs = all_events()
    serialized = [normalize_event(doc) for doc in docs]
    if not include_past:
        serialized = [event for event in serialized if event["status"] != "past"]
    serialized.sort(key=lambda event: (event.get("startsAt") or "", event.get("slug")))
    return serialized


def find_event_by_slug(slug: str) -> tuple[dict | None, dict | None]:
    """Return the normalized event and original document for the given slug."""
    if not slug:
        return None, None
    slug_key = slug.casefold()
    docs = all_events()
    for doc in docs:
        normalized = normalize_event(doc)
        candidates = {(normalized.get("slug") or "").casefold()}
        slug_source = doc.get("name") or doc.get("title")
        if isinstance(slug_source, dict):
            slug_source = slug_source.get("en") or slug_source.get("he")
        fallback_slug = slugify_value(slug_source) if slug_source else ""
        if fallback_slug:
            candidates.add(fallback_slug.casefold())
        slug_override = doc.get("slugOverride")
        if slug_override:
            candidates.add(str(slug_override).casefold())
        explicit_slug = doc.get("slug") or doc.get("slug_en") or doc.get("slug_he")
        if isinstance(explicit_slug, dict):
            explicit_slug = explicit_slug.get("en") or explicit_slug.get("he")
        if explicit_slug:
            candidates.add(str(explicit_slug).casefold())
        if slug_key in candidates:
            return normalized, doc
    return None, None


def unique_dates(events: list[dict]) -> list[dict]:
    seen: dict[str, dict] = {}
    for event in events:
        start = event.get("startsAt")
        if not start:
            continue
        day = start.split("T", 1)[0]
        entry = seen.setdefault(day, {"slug": day, "lastmod": event.get("lastmod"), "eventCount": 0})
        entry["eventCount"] += 1
        if event.get("lastmod") and event["lastmod"] > (entry.get("lastmod") or ""):
            entry["lastmod"] = event["lastmod"]
    results = []
    for slug, payload in seen.items():
        payload["canonicalUrl"] = build_canonical("date", slug=slug)
        results.append(payload)
    results.sort(key=lambda item: item["slug"])
    return results


def aggregate_genres(events: list[dict]) -> list[dict]:
    aggregates: dict[str, dict] = {}
    for event in events:
        for genre in event.get("genres", []):
            slug = genre.get("slug") or ""
            if not slug:
                continue
            entry = aggregates.setdefault(slug, {
                "slug": slug,
                "name": genre.get("name", {"he": "", "en": ""}),
                "canonicalUrl": genre.get("canonicalUrl", build_canonical("genre", slug=slug)),
                "lastmod": event.get("lastmod"),
                "eventCount": 0,
            })
            entry["eventCount"] += 1
            if event.get("lastmod") and event["lastmod"] > (entry.get("lastmod") or ""):
                entry["lastmod"] = event["lastmod"]
    items = list(aggregates.values())
    items.sort(key=lambda item: item["slug"])
    return items


def shard_events(events: list[dict], chunk_size: int = EVENT_SITEMAP_CHUNK) -> list[list[dict]]:
    if chunk_size <= 0:
        return [events]
    return [events[i : i + chunk_size] for i in range(0, len(events), chunk_size)] or [[]]


def format_rfc822(date_str: str | None) -> str | None:
    if not date_str:
        return None
    dt = parse_datetime(date_str)
    if not dt:
        return None
    return format_datetime(dt)


def format_ics(date_str: str | None) -> str | None:
    if not date_str:
        return None
    dt = parse_datetime(date_str)
    if not dt:
        return None
    return dt.strftime("%Y%m%dT%H%M%SZ")


def build_feed(events: list[dict], title: str, url: str, fmt: str) -> str:
    updated = None
    for event in events:
        if event.get("lastmod"):
            if not updated or event["lastmod"] > updated:
                updated = event["lastmod"]
    updated_rfc = format_rfc822(updated) or format_rfc822(datetime.utcnow().replace(tzinfo=timezone.utc).isoformat())

    if fmt == "rss":
        items = []
        for event in events:
            pub = format_rfc822(event.get("startsAt") or event.get("lastmod")) or updated_rfc
            description = event.get("summary", {}).get("en") or event.get("summary", {}).get("he")
            items.append(
                """<item><title>{title}</title><link>{link}</link><guid isPermaLink="true">{link}</guid><pubDate>{pub}</pubDate><description>{desc}</description></item>""".format(
                    title=(event.get("title", {}).get("en") or event.get("title", {}).get("he") or ""),
                    link=event.get("canonicalUrl"),
                    pub=pub,
                    desc=(description or ""),
                )
            )
        return (
            "<?xml version=\"1.0\" encoding=\"UTF-8\"?>"
            f"<rss version=\"2.0\"><channel><title>{title}</title><link>{url}</link><lastBuildDate>{updated_rfc}</lastBuildDate>"
            + "".join(items)
            + "</channel></rss>"
        )
    if fmt == "atom":
        entries = []
        for event in events:
            updated_entry = event.get("lastmod") or updated or ""
            entries.append(
                """<entry><title>{title}</title><id>{link}</id><link href="{link}"/><updated>{updated}</updated><summary>{summary}</summary></entry>""".format(
                    title=(event.get("title", {}).get("en") or event.get("title", {}).get("he") or ""),
                    link=event.get("canonicalUrl"),
                    updated=event.get("lastmod") or updated or "",
                    summary=(event.get("summary", {}).get("en") or event.get("summary", {}).get("he") or ""),
                )
            )
        return (
            "<?xml version=\"1.0\" encoding=\"UTF-8\"?>"
            f"<feed xmlns=\"http://www.w3.org/2005/Atom\"><title>{title}</title><id>{url}</id><updated>{updated or ''}</updated>"
            + "".join(entries)
            + "</feed>"
        )
    # default to json feed
    items = []
    for event in events:
        items.append(
            {
                "id": event.get("canonicalUrl"),
                "url": event.get("canonicalUrl"),
                "title": event.get("title", {}).get("en") or event.get("title", {}).get("he"),
                "summary": event.get("summary", {}).get("en") or event.get("summary", {}).get("he"),
                "date_published": event.get("startsAt"),
                "date_modified": event.get("lastmod"),
            }
        )
    feed = {
        "version": "https://jsonfeed.org/version/1.1",
        "title": title,
        "home_page_url": url,
        "feed_url": url,
        "items": items,
    }
    return json.dumps(feed)


def build_ics(events: list[dict], title: str) -> str:
    lines = [
        "BEGIN:VCALENDAR",
        "VERSION:2.0",
        "PRODID:-//parties247//Events//EN",
        f"X-WR-CALNAME:{title}",
    ]
    generated = format_ics(datetime.utcnow().replace(tzinfo=timezone.utc).isoformat())
    for event in events:
        uid = f"{event.get('slug')}@parties247"
        dtstart = format_ics(event.get("startsAt"))
        dtend = format_ics(event.get("endsAt"))
        dtstamp = format_ics(event.get("lastmod")) or generated
        location = event.get("venue", {}).get("name", {}).get("en") or event.get("venue", {}).get("name", {}).get("he")
        description = event.get("summary", {}).get("en") or event.get("summary", {}).get("he")
        lines.extend(
            [
                "BEGIN:VEVENT",
                f"UID:{uid}",
                f"DTSTAMP:{dtstamp}",
                f"DTSTART:{dtstart}" if dtstart else "",
                f"DTEND:{dtend}" if dtend else "",
                f"SUMMARY:{event.get('title', {}).get('en') or event.get('title', {}).get('he')}",
                f"DESCRIPTION:{description or ''}",
                f"LOCATION:{location or ''}",
                f"URL:{event.get('canonicalUrl')}",
                "END:VEVENT",
            ]
        )
    lines.append("END:VCALENDAR")
    return "\r\n".join(filter(None, lines)) + "\r\n"


def notify_indexers(urls: list[str]):
    unique = sorted({absolute_url(u) for u in urls if u})
    if not unique:
        return
    payload = {
        "urls": unique,
        "timestamp": datetime.utcnow().isoformat(),
    }
    record_setting_hit("indexing:lastPing", {"urls": unique, "timestamp": payload["timestamp"]})
    if INDEXNOW_KEY:
        indexnow_payload = {
            "host": urlparse(CANONICAL_BASE_URL).netloc,
            "key": INDEXNOW_KEY,
            "keyLocation": INDEXNOW_KEY_LOCATION or absolute_url("/indexnow.txt"),
            "urlList": unique,
        }
        try:
            requests.post(INDEXNOW_ENDPOINT, json=indexnow_payload, timeout=5)
        except Exception as exc:  # pragma: no cover - network best effort
            app.logger.warning(f"IndexNow ping failed: {exc}")
    sitemap_url = build_canonical("sitemap_index")
    for ping_url in (
        f"https://www.google.com/ping?sitemap={quote_plus(sitemap_url)}",
        f"https://www.bing.com/ping?sitemap={quote_plus(sitemap_url)}",
    ):
        try:
            requests.get(ping_url, timeout=5)
        except Exception as exc:  # pragma: no cover
            app.logger.warning(f"Search engine ping failed: {exc}")


def trigger_revalidation(paths: list[str]):
    if not REVALIDATE_ENDPOINT or not paths:
        return
    payload = {"paths": paths}
    if REVALIDATE_SECRET:
        payload["secret"] = REVALIDATE_SECRET
    try:
        requests.post(REVALIDATE_ENDPOINT, json=payload, timeout=5)
        record_setting_hit("indexing:lastRevalidate", {"paths": paths})
    except Exception as exc:  # pragma: no cover
        app.logger.warning(f"Revalidation webhook failed: {exc}")

# --- Security ---
JWT_SECRET = os.environ.get("JWT_SECRET_KEY", "")
ADMIN_HASH = os.environ.get("ADMIN_PASSWORD_HASH", "").encode()

def protect(f):
    @wraps(f)
    def decorated_function(*args, **kwargs):
        if not JWT_SECRET:
            app.logger.error("JWT secret not configured; rejecting protected request.")
            return jsonify({"message": "Server misconfigured."}), 500
        auth_header = request.headers.get("Authorization", "")
        if auth_header.startswith("Bearer "):
            token = auth_header.split(" ", 1)[1].strip()
            try:
                jwt.decode(token, JWT_SECRET, algorithms=["HS256"])
                return f(*args, **kwargs)
            except jwt.ExpiredSignatureError:
                return jsonify({"message": "Token expired."}), 401
            except jwt.InvalidTokenError:
                return jsonify({"message": "Invalid token."}), 401
        return jsonify({"message": "Unauthorized."}), 401
    return decorated_function

def apply_security_headers(response):
    """Apply a minimal set of security headers on every response."""
    headers = getattr(response, "headers", None)
    if headers is None:
        return response
    headers.setdefault("X-Content-Type-Options", "nosniff")
    headers.setdefault("X-Frame-Options", "DENY")
    headers.setdefault("Referrer-Policy", "same-origin")
    headers.setdefault("X-XSS-Protection", "1; mode=block")
    return response


if hasattr(app, "after_request"):
    app.after_request(apply_security_headers)


@app.route("/api/health", methods=["GET"])
def health():
    """Lightweight health-check endpoint used by monitoring probes."""
    return jsonify({"status": "ok"}), 200


def _parse_device_type(user_agent_str: str | None) -> str:
    """Derive device type from User-Agent string."""
    if not user_agent_str:
        return "unknown"
    ua = user_agent_str.lower()
    if any(k in ua for k in ("mobile", "android", "iphone", "ipod", "windows phone")):
        return "mobile"
    if any(k in ua for k in ("ipad", "tablet")):
        return "tablet"
    if any(k in ua for k in ("bot", "crawl", "spider", "lighthouse")):
        return "bot"
    return "desktop"


def _parse_browser(user_agent_str: str | None) -> str:
    """Derive browser name from User-Agent string."""
    if not user_agent_str:
        return "unknown"
    ua = user_agent_str.lower()
    if "edg" in ua:
        return "Edge"
    if "opr" in ua or "opera" in ua:
        return "Opera"
    if "chrome" in ua and "safari" in ua:
        return "Chrome"
    if "firefox" in ua:
        return "Firefox"
    if "safari" in ua:
        return "Safari"
    if "msie" in ua or "trident" in ua:
        return "IE"
    return "Other"


def _parse_os(user_agent_str: str | None) -> str:
    """Derive OS from User-Agent string."""
    if not user_agent_str:
        return "unknown"
    ua = user_agent_str.lower()
    if "windows" in ua:
        return "Windows"
    if "mac os" in ua or "macintosh" in ua:
        return "macOS"
    if "iphone" in ua or "ipad" in ua:
        return "iOS"
    if "android" in ua:
        return "Android"
    if "linux" in ua:
        return "Linux"
    return "Other"


def _parse_referrer_source(referrer: str | None, utm_source: str | None) -> str:
    """Categorize traffic source from referrer URL or UTM source."""
    if utm_source:
        return sanitize_analytics_text(utm_source) or "direct"
    if not referrer:
        return "direct"
    ref = referrer.lower()
    if any(d in ref for d in ("google.", "bing.", "yahoo.", "duckduckgo.", "yandex.")):
        return "organic_search"
    if any(d in ref for d in ("facebook.", "fb.", "instagram.", "t.co", "twitter.", "x.com", "tiktok.", "linkedin.", "whatsapp.")):
        return "social"
    if any(d in ref for d in ("parties247", "localhost")):
        return "direct"
    return "referral"


@app.route("/api/analytics/visitor", methods=["POST"])
@limiter.limit("120 per minute")
def record_unique_visitor():
    """Record a unique visitor session with enriched context data."""
    if visitor_analytics_collection is None:
        return jsonify({"message": "Analytics datastore unavailable."}), 503
    payload = request.get_json(silent=True) or {}
    try:
        body = AnalyticsVisitorRequest(**payload)
    except ValidationError as exc:
        errors = exc.errors() if hasattr(exc, "errors") else []
        return jsonify({"message": "Invalid analytics event.", "errors": errors}), 400

    session_id = sanitize_analytics_text(body.sessionId)
    if not session_id:
        return jsonify({"message": "Invalid analytics event.", "errors": [{"loc": ["sessionId"], "msg": "sessionId is required."}]}), 400

    now = datetime.now(timezone.utc)
    user_agent = sanitize_analytics_text(request.headers.get("User-Agent"))
    referer = sanitize_analytics_text(body.referrer or request.headers.get("Referer"))
    client_ip = sanitize_analytics_text(extract_client_ip(request))

    record = {
        "sessionId": session_id,
        "createdAt": now,
    }

    if user_agent:
        record["userAgent"] = user_agent
        record["deviceType"] = _parse_device_type(user_agent)
        record["browser"] = _parse_browser(user_agent)
        record["os"] = _parse_os(user_agent)
    if referer:
        record["referer"] = referer
    if client_ip:
        record["clientIp"] = client_ip

    # Page context
    if body.pageUrl:
        record["pageUrl"] = sanitize_analytics_text(body.pageUrl)
    if body.language:
        record["language"] = sanitize_analytics_text(body.language)
    if body.timezone:
        record["timezone"] = sanitize_analytics_text(body.timezone)
    if body.screenWidth and body.screenHeight:
        record["screen"] = f"{body.screenWidth}x{body.screenHeight}"

    # UTM parameters
    utm = {}
    if body.utmSource:
        utm["source"] = sanitize_analytics_text(body.utmSource)
    if body.utmMedium:
        utm["medium"] = sanitize_analytics_text(body.utmMedium)
    if body.utmCampaign:
        utm["campaign"] = sanitize_analytics_text(body.utmCampaign)
    if body.utmTerm:
        utm["term"] = sanitize_analytics_text(body.utmTerm)
    if body.utmContent:
        utm["content"] = sanitize_analytics_text(body.utmContent)
    if utm:
        record["utm"] = utm

    # Traffic source classification
    record["trafficSource"] = _parse_referrer_source(referer, body.utmSource)

    try:
        visitor_analytics_collection.update_one(
            {"sessionId": session_id},
            {"$set": record},
            upsert=True,
        )
    except Exception as exc:  # pragma: no cover - best effort persistence
        app.logger.error(f"Failed to persist visitor analytics: {exc}")
        return jsonify({"message": "Failed to record analytics event."}), 500

    return jsonify({"message": "Recorded"}), 202


def persist_party_metric(party: dict | None, metric: str) -> tuple[bool, str | None]:
    """Persist the requested metric for the provided party document."""

    if party_analytics_collection is None:
        return False, "unavailable"

    if not party:
        return False, "not_found"

    party_identifier = party.get("_id")
    if party_identifier is None:
        return False, "not_found"

    if not is_party_live(party):
        try:
            party_analytics_collection.delete_one({"partyId": str(party_identifier)})
        except Exception:  # pragma: no cover - best effort cleanup
            pass
        return False, "archived"

    now = datetime.now(timezone.utc)
    party_id = str(party_identifier)
    slug = sanitize_analytics_text(party.get("slug"))
    name = sanitize_analytics_text(party.get("name"))
    party_date = isoformat_or_none(party.get("date") or party.get("startsAt"))

    update = {
        "$set": {
            "partyId": party_id,
            "partySlug": slug,
            "partyName": name,
            "partyDate": party_date,
            "updatedAt": now,
        },
        "$inc": {metric: 1},
    }

    initial_metrics = {"views": 0, "redirects": 0}
    initial_metrics.pop(metric, None)
    if initial_metrics:
        update["$setOnInsert"] = initial_metrics
    if metric == "views":
        update["$set"]["lastViewedAt"] = now
    elif metric == "redirects":
        update["$set"]["lastRedirectAt"] = now

    try:
        party_analytics_collection.update_one({"partyId": party_id}, update, upsert=True)
    except Exception as exc:  # pragma: no cover - best effort persistence
        app.logger.error(f"Failed to persist party analytics: {exc}")
        return False, "error"

    return True, None


def record_party_interaction(metric: str):
    if party_analytics_collection is None or parties_collection is None:
        return jsonify({"message": "Analytics datastore unavailable."}), 503

    payload = request.get_json(silent=True) or {}
    try:
        body = PartyAnalyticsRequest(**payload)
    except ValidationError as exc:
        errors = exc.errors() if hasattr(exc, "errors") else []
        return jsonify({"message": "Invalid analytics event.", "errors": errors}), 400

    if not (body.partyId or body.partySlug):
        return jsonify({"message": "Invalid analytics event.", "errors": [{"loc": ["partyId", "partySlug"], "msg": "Provide partyId or partySlug."}]}), 400

    party_id_input = body.partyId.strip() if isinstance(body.partyId, str) else body.partyId
    party_slug_input = sanitize_analytics_text(body.partySlug)

    party = find_party_for_analytics(party_id_input, party_slug_input)
    if not party:
        return jsonify({"message": "Party not found."}), 404

    success, reason = persist_party_metric(party, metric)
    if success:
        # Also log to main event stream for time-series aggregation with visitor context
        if analytics_collection is not None:
            try:
                user_agent = sanitize_analytics_text(request.headers.get("User-Agent"))
                client_ip = sanitize_analytics_text(extract_client_ip(request))
                referer = sanitize_analytics_text(body.referrer or request.headers.get("Referer"))
                session_id = sanitize_analytics_text(body.sessionId)

                record = {
                    "category": "party",
                    "action": "view" if metric == "views" else "redirect",
                    "label": sanitize_analytics_text(party.get("slug")),
                    "partyId": str(party["_id"]),
                    "partyName": sanitize_analytics_text(party.get("name")),
                    "createdAt": datetime.now(timezone.utc),
                    "context": {"partyId": str(party["_id"]), "metric": metric},
                }
                if session_id:
                    record["sessionId"] = session_id
                if user_agent:
                    record["userAgent"] = user_agent
                    record["deviceType"] = _parse_device_type(user_agent)
                if client_ip:
                    record["clientIp"] = client_ip
                if referer:
                    record["referer"] = referer
                    record["trafficSource"] = _parse_referrer_source(referer, None)

                analytics_collection.insert_one(record)
            except Exception as e:
                app.logger.error(f"Failed to log party stream event: {e}")

        return jsonify({"message": "Recorded"}), 202

    if reason == "archived":
        return jsonify({"message": "Party is archived."}), 410
    if reason == "unavailable":
        return jsonify({"message": "Analytics datastore unavailable."}), 503
    if reason == "error":
        return jsonify({"message": "Failed to record analytics event."}), 500

    return jsonify({"message": "Party not found."}), 404


@app.route("/api/analytics/party-view", methods=["POST"])
@limiter.limit("240 per minute")
def record_party_view():
    """Increment the view counter for a party analytics record."""
    return record_party_interaction("views")


@app.route("/api/analytics/party-redirect", methods=["POST"])
@limiter.limit("240 per minute")
def record_party_redirect():
    """Increment the redirect counter for a party analytics record."""
    return record_party_interaction("redirects")


@app.route("/api/analytics/summary", methods=["GET"])
@limiter.limit("30 per minute")
def analytics_summary():
    """Return aggregated analytics collected within the reporting window."""
    try:
        summary = build_analytics_summary()
    except RuntimeError:
        return jsonify({"message": "Analytics datastore unavailable."}), 503
    except Exception as exc:  # pragma: no cover - defensive
        app.logger.error(f"Failed to build analytics summary: {exc}")
        return jsonify({"message": "Failed to build analytics summary."}), 500
    return jsonify(summary), 200


@app.route("/api/analytics/recent", methods=["GET"])
@limiter.limit("30 per minute")
def analytics_recent():
    """Return the most recent analytics events for the live activity feed."""
    if analytics_collection is None and visitor_analytics_collection is None:
        return jsonify({"events": []}), 200

    events = []
    now = datetime.now(timezone.utc)
    cutoff = now - timedelta(hours=24)

    # Fetch recent party events (views + redirects)
    if analytics_collection is not None:
        try:
            party_query = {"createdAt": {"$gte": cutoff}, "category": "party"}
            try:
                party_docs = list(
                    analytics_collection.find(party_query).sort("createdAt", -1).limit(50)
                )
            except TypeError:
                party_docs = list(analytics_collection.find(party_query))
                party_docs.sort(key=lambda d: d.get("createdAt", ""), reverse=True)
                party_docs = party_docs[:50]

            for doc in party_docs:
                action = doc.get("action", "view")
                event_type = "purchase" if action == "redirect" else "view"
                device_type = doc.get("deviceType") or _parse_device_type(doc.get("userAgent"))
                source = doc.get("trafficSource") or _parse_referrer_source(doc.get("referer"), None)

                details_parts = []
                if device_type and device_type != "unknown":
                    details_parts.append(f" {device_type}" if device_type == "mobile" else f" {device_type}")
                if source and source != "direct":
                    details_parts.append(f" {source}")

                events.append({
                    "id": str(doc.get("_id", "")),
                    "type": event_type,
                    "partyName": doc.get("partyName") or doc.get("label") or "",
                    "partyId": doc.get("partyId") or "",
                    "timestamp": isoformat_or_none(doc.get("createdAt")) or now.isoformat(),
                    "details": "  ".join(details_parts) if details_parts else None,
                })
        except Exception as exc:
            app.logger.error(f"Failed to read recent party events: {exc}")

    # Fetch recent visitor sessions
    if visitor_analytics_collection is not None:
        try:
            visitor_query = {"createdAt": {"$gte": cutoff}}
            try:
                visitor_docs = list(
                    visitor_analytics_collection.find(visitor_query).sort("createdAt", -1).limit(20)
                )
            except TypeError:
                visitor_docs = list(visitor_analytics_collection.find(visitor_query))
                visitor_docs.sort(key=lambda d: d.get("createdAt", ""), reverse=True)
                visitor_docs = visitor_docs[:20]

            for doc in visitor_docs:
                device_type = doc.get("deviceType") or _parse_device_type(doc.get("userAgent"))
                source = doc.get("trafficSource") or _parse_referrer_source(doc.get("referer"), None)
                browser = doc.get("browser") or _parse_browser(doc.get("userAgent"))

                details_parts = []
                if device_type and device_type != "unknown":
                    details_parts.append(f" {device_type}" if device_type == "mobile" else f" {device_type}")
                if browser and browser != "unknown":
                    details_parts.append(browser)
                if source and source != "direct":
                    details_parts.append(f" {source}")
                elif source == "direct":
                    details_parts.append("")

                events.append({
                    "id": str(doc.get("_id", "")),
                    "type": "visit",
                    "partyName": None,
                    "partyId": None,
                    "timestamp": isoformat_or_none(doc.get("createdAt")) or now.isoformat(),
                    "details": "  ".join(details_parts) if details_parts else None,
                })
        except Exception as exc:
            app.logger.error(f"Failed to read recent visitors: {exc}")

    # Sort all events by timestamp descending and limit
    events.sort(key=lambda e: e.get("timestamp", ""), reverse=True)
    events = events[:50]

    return jsonify({"events": events}), 200


@app.route("/api/admin/analytics/visitors", methods=["GET"])
@protect
def analytics_visitors():
    """Return detailed visitor data with device, browser, traffic source info."""
    if visitor_analytics_collection is None:
        return jsonify({"message": "Analytics datastore unavailable."}), 503

    range_param = request.args.get("range", "24h")
    now = datetime.now(timezone.utc)

    if range_param == "7d":
        cutoff = now - timedelta(days=7)
    elif range_param == "30d":
        cutoff = now - timedelta(days=30)
    else:
        cutoff = now - timedelta(hours=24)

    try:
        try:
            docs = list(visitor_analytics_collection.find({"createdAt": {"$gte": cutoff}}))
        except TypeError:
            docs = list(visitor_analytics_collection.find())
    except Exception as exc:
        app.logger.error(f"Failed to read visitor analytics: {exc}")
        return jsonify({"message": "Failed to read visitor analytics."}), 500

    # Build aggregated breakdowns
    device_counts = {}
    browser_counts = {}
    os_counts = {}
    source_counts = {}
    language_counts = {}
    referrer_domains = {}
    total = 0

    visitors_list = []
    for doc in docs:
        created_at = parse_datetime(doc.get("createdAt"))
        if created_at and created_at < cutoff:
            continue
        total += 1

        device = doc.get("deviceType") or _parse_device_type(doc.get("userAgent"))
        browser = doc.get("browser") or _parse_browser(doc.get("userAgent"))
        os_name = doc.get("os") or _parse_os(doc.get("userAgent"))
        source = doc.get("trafficSource") or _parse_referrer_source(doc.get("referer"), (doc.get("utm") or {}).get("source"))
        lang = doc.get("language") or "unknown"

        device_counts[device] = device_counts.get(device, 0) + 1
        browser_counts[browser] = browser_counts.get(browser, 0) + 1
        os_counts[os_name] = os_counts.get(os_name, 0) + 1
        source_counts[source] = source_counts.get(source, 0) + 1
        language_counts[lang] = language_counts.get(lang, 0) + 1

        ref = doc.get("referer")
        if ref:
            try:
                domain = urlparse(ref).netloc or ref
                referrer_domains[domain] = referrer_domains.get(domain, 0) + 1
            except Exception:
                pass

        visitors_list.append({
            "sessionId": doc.get("sessionId"),
            "timestamp": isoformat_or_none(doc.get("createdAt")),
            "deviceType": device,
            "browser": browser,
            "os": os_name,
            "trafficSource": source,
            "referer": doc.get("referer"),
            "language": lang,
            "screen": doc.get("screen"),
            "pageUrl": doc.get("pageUrl"),
            "utm": doc.get("utm"),
        })

    visitors_list.sort(key=lambda v: v.get("timestamp") or "", reverse=True)

    def to_breakdown(d):
        items = sorted(d.items(), key=lambda x: x[1], reverse=True)
        return [{"label": k, "count": v, "percent": round(v / total * 100, 1) if total > 0 else 0} for k, v in items]

    return jsonify({
        "total": total,
        "range": range_param,
        "devices": to_breakdown(device_counts),
        "browsers": to_breakdown(browser_counts),
        "operatingSystems": to_breakdown(os_counts),
        "trafficSources": to_breakdown(source_counts),
        "languages": to_breakdown(language_counts),
        "topReferrers": to_breakdown(referrer_domains),
        "visitors": visitors_list[:100],
    }), 200


@app.route("/api/admin/analytics/detailed", methods=["GET"])
@protect
def analytics_detailed():
    """Return time-series analytics for visits, views, and purchases."""
    start_str = request.args.get("start")
    end_str = request.args.get("end")
    range_param = request.args.get("range", "7d")
    interval = request.args.get("interval", "day")
    party_slug = request.args.get("partyId")
    
    now = datetime.now(timezone.utc)
    
    start = None
    end = None
    
    # Parse provided dates
    if start_str and end_str:
        start = parse_datetime(start_str)
        end = parse_datetime(end_str)
    
    # Use presets if no custom range
    if not start:
        if range_param == "24h":
            start = now - timedelta(hours=24)
            end = now
        elif range_param == "30d":
            start = now - timedelta(days=30)
            end = now
        else:
            # default 7d
            start = now - timedelta(days=7)
            end = now
            
    if not end:
        end = now

    if party_slug:
        # Validate party existence to prevent confusion (e.g. passing "hour" as partyId)
        if not find_party_for_analytics(party_slug, party_slug):
             return jsonify({"message": f"Party '{party_slug}' not found."}), 404

    try:
        data = build_time_series_analytics(start, end, interval, party_slug)
    except RuntimeError:
        return jsonify({"message": "Analytics datastore unavailable."}), 503
    except Exception as exc:
        app.logger.error(f"Failed to build detailed analytics: {exc}")
        return jsonify({"message": "Failed to build detailed analytics."}), 500
        
    return jsonify({
        "data": data,
        "range": range_param,
        "interval": interval,
        "partyId": party_slug
    }), 200


@app.route("/analytics", methods=["GET"])
def analytics_page():
    """Render a lightweight HTML dashboard summarizing analytics events."""
    try:
        summary = build_analytics_summary()
    except RuntimeError:
        body = """<!doctype html><html lang='en'><head><meta charset='utf-8'><title>Analytics</title></head><body><h1>Analytics</h1><p>Analytics datastore unavailable.</p></body></html>"""
        return body, 503, {"Content-Type": "text/html; charset=utf-8"}
    except Exception as exc:  # pragma: no cover - defensive
        app.logger.error(f"Failed to render analytics dashboard: {exc}")
        body = """<!doctype html><html lang='en'><head><meta charset='utf-8'><title>Analytics</title></head><body><h1>Analytics</h1><p>Unable to render analytics dashboard.</p></body></html>"""
        return body, 500, {"Content-Type": "text/html; charset=utf-8"}

    parties = summary.get("parties", [])
    unique_visitors = summary.get("uniqueVisitors24h", 0)

    if parties:
        rows = "".join(
            "<tr>"
            + "".join(
                f"<td>{html.escape(str(value))}</td>"
                for value in (
                    item.get("name") or "",
                    item.get("slug") or "",
                    item.get("date") or "",
                    item.get("views", 0),
                    item.get("redirects", 0),
                )
            )
            + "</tr>"
            for item in parties
        )
    else:
        rows = "<tr><td colspan='5'>No live parties found.</td></tr>"

    body = f"""<!doctype html>
<html lang='en'>
  <head>
    <meta charset='utf-8'>
    <title>Analytics dashboard</title>
    <meta name='viewport' content='width=device-width, initial-scale=1'>
    <style>
      body {{ font-family: system-ui, -apple-system, 'Segoe UI', sans-serif; margin: 0; padding: 2rem; background-color: #f8fafc; color: #0f172a; }}
      h1 {{ margin-top: 0; }}
      section {{ background: #ffffff; padding: 1.5rem; margin-bottom: 1.5rem; border-radius: 12px; box-shadow: 0 10px 20px rgba(15, 23, 42, 0.08); }}
      table {{ width: 100%; border-collapse: collapse; margin-top: 0.5rem; }}
      th, td {{ text-align: left; padding: 0.5rem; border-bottom: 1px solid #e2e8f0; }}
      th {{ font-size: 0.85rem; text-transform: uppercase; letter-spacing: 0.08em; color: #475569; }}
      td {{ font-size: 0.95rem; }}
      .stats {{ display: flex; gap: 1rem; flex-wrap: wrap; margin-bottom: 2rem; }}
      .stat {{ background: linear-gradient(135deg, #6366f1, #8b5cf6); color: white; padding: 1.25rem 1.5rem; border-radius: 16px; min-width: 200px; box-shadow: 0 20px 25px -15px rgba(99, 102, 241, 0.8); }}
      .stat strong {{ display: block; font-size: 2rem; line-height: 1.1; margin-bottom: 0.25rem; }}
    </style>
  </head>
  <body>
    <h1>Parties247 analytics</h1>
    <div class='stats'>
      <div class='stat'>
        <strong>{unique_visitors}</strong>
        <span>Unique visitors (last 24h)</span>
      </div>
      <div class='stat'>
        <strong>{len(parties)}</strong>
        <span>Live parties tracked</span>
      </div>
    </div>
    <section>
      <h2>Live party performance</h2>
      <table>
        <thead>
          <tr>
            <th>Name</th>
            <th>Slug</th>
            <th>Date</th>
            <th>Views</th>
            <th>Redirects</th>
          </tr>
        </thead>
        <tbody>
          {rows}
        </tbody>
      </table>
    </section>
  </body>
</html>"""

    return body, 200, {"Content-Type": "text/html; charset=utf-8"}


OPENAPI_TEMPLATE = {
    "openapi": "3.1.0",
    "info": {
        "title": "Parties247 API",
        "version": "1.0.0",
        "description": "REST API for reading party data and managing the Parties247 catalog.",
        "contact": {
            "name": "Parties247",
            "url": "https://parties247-website.vercel.app",
        },
    },
    "paths": {
        "/api/health": {
            "get": {
                "summary": "Health check",
                "description": "Returns a simple status payload indicating the API is responsive.",
                "responses": {
                    "200": {
                        "description": "Service is healthy.",
                        "content": {
                            "application/json": {
                                "schema": {
                                    "type": "object",
                                    "properties": {
                                        "status": {"type": "string", "example": "ok"}
                                    },
                                }
                            }
                        },
                    }
                },
            }
        },
        "/api/analytics/visitor": {
            "post": {
                "summary": "Record unique visitor",
                "description": "Mark a visitor session as active within the last 24 hours.",
                "requestBody": {
                    "required": True,
                    "content": {
                        "application/json": {
                            "schema": {"$ref": "#/components/schemas/AnalyticsVisitorRequest"}
                        }
                    }
                },
                "responses": {
                    "202": {
                        "description": "Visitor was recorded successfully.",
                        "content": {
                            "application/json": {
                                "schema": {
                                    "type": "object",
                                    "properties": {
                                        "message": {"type": "string", "example": "Recorded"}
                                    }
                                }
                            }
                        }
                    },
                    "400": {
                        "description": "Invalid analytics payload.",
                        "content": {
                            "application/json": {
                                "schema": {
                                    "type": "object",
                                    "properties": {
                                        "message": {"type": "string"},
                                        "errors": {"type": "array", "items": {"type": "object"}}
                                    }
                                }
                            }
                        }
                    },
                    "503": {
                        "description": "Analytics datastore unavailable.",
                        "content": {
                            "application/json": {
                                "schema": {
                                    "type": "object",
                                    "properties": {
                                        "message": {"type": "string"}
                                    }
                                }
                            }
                        }
                    }
                }
            }
        },
        "/api/analytics/party-view": {
            "post": {
                "summary": "Record party view",
                "description": "Increment the view counter when a party page is opened.",
                "requestBody": {
                    "required": True,
                    "content": {
                        "application/json": {
                            "schema": {"$ref": "#/components/schemas/PartyAnalyticsRequest"}
                        }
                    }
                },
                "responses": {
                    "202": {
                        "description": "View was recorded successfully.",
                        "content": {
                            "application/json": {
                                "schema": {
                                    "type": "object",
                                    "properties": {
                                        "message": {"type": "string", "example": "Recorded"}
                                    }
                                }
                            }
                        }
                    },
                    "400": {
                        "description": "Invalid analytics payload.",
                        "content": {
                            "application/json": {
                                "schema": {
                                    "type": "object",
                                    "properties": {
                                        "message": {"type": "string"},
                                        "errors": {"type": "array", "items": {"type": "object"}}
                                    }
                                }
                            }
                        }
                    },
                    "404": {"description": "Party not found."},
                    "410": {"description": "Party archived."},
                    "503": {
                        "description": "Analytics datastore unavailable.",
                        "content": {
                            "application/json": {
                                "schema": {
                                    "type": "object",
                                    "properties": {
                                        "message": {"type": "string"}
                                    }
                                }
                            }
                        }
                    }
                }
            }
        },
        "/api/analytics/party-redirect": {
            "post": {
                "summary": "Record party redirect",
                "description": "Increment the redirect counter when a user clicks a purchase link for the party.",
                "requestBody": {
                    "required": True,
                    "content": {
                        "application/json": {
                            "schema": {"$ref": "#/components/schemas/PartyAnalyticsRequest"}
                        }
                    }
                },
                "responses": {
                    "202": {
                        "description": "Redirect was recorded successfully.",
                        "content": {
                            "application/json": {
                                "schema": {
                                    "type": "object",
                                    "properties": {
                                        "message": {"type": "string", "example": "Recorded"}
                                    }
                                }
                            }
                        }
                    },
                    "400": {
                        "description": "Invalid analytics payload.",
                        "content": {
                            "application/json": {
                                "schema": {
                                    "type": "object",
                                    "properties": {
                                        "message": {"type": "string"},
                                        "errors": {"type": "array", "items": {"type": "object"}}
                                    }
                                }
                            }
                        }
                    },
                    "404": {"description": "Party not found."},
                    "410": {"description": "Party archived."},
                    "503": {
                        "description": "Analytics datastore unavailable.",
                        "content": {
                            "application/json": {
                                "schema": {
                                    "type": "object",
                                    "properties": {
                                        "message": {"type": "string"}
                                    }
                                }
                            }
                        }
                    }
                }
            }
        },
        "/api/analytics/summary": {
            "get": {
                "summary": "Analytics summary",
                "description": "Retrieve live party analytics including view and redirect totals plus unique visitors recorded in the last 24 hours.",
                "responses": {
                    "200": {
                        "description": "Aggregated analytics counters.",
                        "content": {
                            "application/json": {
                                "schema": {"$ref": "#/components/schemas/AnalyticsSummary"}
                            }
                        }
                    },
                    "503": {
                        "description": "Analytics datastore unavailable.",
                        "content": {
                            "application/json": {
                                "schema": {
                                    "type": "object",
                                    "properties": {
                                        "message": {"type": "string"}
                                    }
                                }
                            }
                        }
                    }
                }
            }
        },
        "/api/admin/analytics/detailed": {
            "get": {
                "summary": "Detailed time-series analytics",
                "description": "Retrieve hourly or daily analytics metrics including website visits, party views, and purchases. Requires admin authentication.",
                "security": [{"bearerAuth": []}],
                "parameters": [
                    {
                        "name": "start",
                        "in": "query",
                        "schema": {"type": "string", "format": "date-time"},
                        "description": "Start date/time (ISO 8601 format). If not provided, uses preset range."
                    },
                    {
                        "name": "end",
                        "in": "query",
                        "schema": {"type": "string", "format": "date-time"},
                        "description": "End date/time (ISO 8601 format). If not provided, uses preset range."
                    },
                    {
                        "name": "range",
                        "in": "query",
                        "schema": {"type": "string", "enum": ["24h", "7d", "30d"], "default": "7d"},
                        "description": "Preset time range. Ignored if start/end are provided."
                    },
                    {
                        "name": "interval",
                        "in": "query",
                        "schema": {"type": "string", "enum": ["hour", "day"], "default": "day"},
                        "description": "Time bucket granularity for aggregation."
                    },
                    {
                        "name": "partyId",
                        "in": "query",
                        "schema": {"type": "string"},
                        "description": "Optional party slug to filter metrics to a specific party."
                    }
                ],
                "responses": {
                    "200": {
                        "description": "Time-series analytics data.",
                        "content": {
                            "application/json": {
                                "schema": {
                                    "type": "object",
                                    "properties": {
                                        "data": {
                                            "type": "array",
                                            "items": {
                                                "type": "object",
                                                "properties": {
                                                    "timestamp": {"type": "string", "description": "ISO timestamp or date for the bucket"},
                                                    "visits": {"type": "integer", "description": "Unique website visits in this period"},
                                                    "partyViews": {"type": "integer", "description": "Total party page views in this period"},
                                                    "purchases": {"type": "integer", "description": "Ticket purchase clicks in this period"}
                                                }
                                            }
                                        },
                                        "range": {"type": "string"},
                                        "interval": {"type": "string"},
                                        "partyId": {"type": "string", "nullable": True}
                                    }
                                }
                            }
                        }
                    },
                    "401": {"description": "Unauthorized - valid admin token required."},
                    "503": {"description": "Analytics datastore unavailable."}
                }
            }
        },
        "/api/parties": {
            "get": {
                "summary": "List parties",
                "description": "Fetch the public parties currently tracked by Parties247.",
                "parameters": [
                    {
                        "name": "date",
                        "in": "query",
                        "required": False,
                        "schema": {"type": "string", "format": "date"},
                        "description": "ISO-8601 date (YYYY-MM-DD) used to filter results to a specific calendar day.",
                    },
                    {
                        "name": "upcoming",
                        "in": "query",
                        "required": False,
                        "schema": {"type": "boolean"},
                        "description": "When true, limit results to parties occurring today or later.",
                    },
                ],
                "responses": {
                    "200": {
                        "description": "Array of party objects.",
                        "content": {
                            "application/json": {
                                "schema": {
                                    "type": "array",
                                    "items": {"$ref": "#/components/schemas/Party"},
                                }
                            }
                        },
                    },
                    "400": {
                        "description": "Invalid query parameters.",
                        "content": {
                            "application/json": {
                                "schema": {
                                    "type": "object",
                                    "properties": {
                                        "message": {"type": "string"},
                                    },
                                },
                            }
                        },
                    },
                    "500": {
                        "description": "Unexpected error fetching parties.",
                        "content": {
                            "application/json": {
                                "schema": {
                                    "type": "object",
                                    "properties": {
                                        "message": {"type": "string"},
                                        "error": {"type": "string"},
                                    },
                                }
                            }
                        },
                    },
                },
            }
        },
        "/api/events": {
            "get": {
                "summary": "Events feed",
                "description": "Return a denormalized events list used by downstream integrations.",
                "responses": {
                    "200": {
                        "description": "Events response payload.",
                        "content": {
                            "application/json": {
                                "schema": {
                                    "type": "object",
                                    "properties": {
                                        "generatedAt": {"type": "string", "format": "date-time"},
                                        "items": {
                                            "type": "array",
                                            "items": {"$ref": "#/components/schemas/Event"},
                                        },
                                    },
                                }
                            }
                        },
                    }
                },
            }
        },
        "/api/events/{slug}": {
            "get": {
                "summary": "Event detail",
                "description": "Fetch a single event by slug, including purchase links when available.",
                "parameters": [
                    {
                        "name": "slug",
                        "in": "path",
                        "required": True,
                        "schema": {"type": "string"},
                        "description": "Event slug, e.g. `thursday-moon-02-10`."
                    }
                ],
                "responses": {
                    "200": {
                        "description": "Event payload containing metadata and purchase URLs.",
                        "content": {
                            "application/json": {
                                "schema": {
                                    "type": "object",
                                    "properties": {
                                        "generatedAt": {"type": "string", "format": "date-time"},
                                        "event": {"$ref": "#/components/schemas/Event"},
                                    },
                                }
                            }
                        },
                    },
                    "404": {
                        "description": "Event could not be found.",
                        "content": {
                            "application/json": {
                                "schema": {
                                    "type": "object",
                                    "properties": {
                                        "message": {"type": "string"}
                                    },
                                }
                            }
                        },
                    },
                },
            }
        },
        "/api/cities": {
            "get": {
                "summary": "List cities",
                "description": "Aggregate the number of parties per city.",
                "responses": {
                    "200": {
                        "description": "List of cities with event counts.",
                        "content": {
                            "application/json": {
                                "schema": {
                                    "type": "object",
                                    "properties": {
                                        "generatedAt": {"type": "string", "format": "date-time"},
                                        "items": {
                                            "type": "array",
                                            "items": {"$ref": "#/components/schemas/Dimension"},
                                        },
                                    },
                                }
                            }
                        },
                    }
                },
            }
        },
        "/api/venues": {
            "get": {
                "summary": "List venues",
                "description": "Aggregate the number of parties per venue.",
                "responses": {
                    "200": {
                        "description": "List of venues with event counts.",
                        "content": {
                            "application/json": {
                                "schema": {
                                    "type": "object",
                                    "properties": {
                                        "generatedAt": {"type": "string", "format": "date-time"},
                                        "items": {
                                            "type": "array",
                                            "items": {"$ref": "#/components/schemas/Dimension"},
                                        },
                                    },
                                }
                            }
                        },
                    }
                },
            }
        },
        "/api/genres": {
            "get": {
                "summary": "List genres",
                "description": "Aggregate the number of parties per genre.",
                "responses": {
                    "200": {
                        "description": "List of genres with event counts.",
                        "content": {
                            "application/json": {
                                "schema": {
                                    "type": "object",
                                    "properties": {
                                        "generatedAt": {"type": "string", "format": "date-time"},
                                        "items": {
                                            "type": "array",
                                            "items": {"$ref": "#/components/schemas/Dimension"},
                                        },
                                    },
                                }
                            }
                        },
                    }
                },
            }
        },
        "/api/tags": {
            "get": {
                "summary": "List tags",
                "description": "Return the curated tags available for parties.",
                "responses": {
                    "200": {
                        "description": "List of tags.",
                        "content": {
                            "application/json": {
                                "schema": {
                                    "type": "array",
                                    "items": {"$ref": "#/components/schemas/Tag"},
                                }
                            }
                        },
                    }
                },
            }
        },
        "/api/referral": {
            "get": {
                "summary": "Get referral configuration",
                "description": "Expose the configured default referral code used in external links.",
                "responses": {
                    "200": {
                        "description": "Referral configuration payload.",
                        "content": {
                            "application/json": {
                                "schema": {
                                    "type": "object",
                                    "properties": {
                                        "referral": {"type": "string", "nullable": True}
                                    },
                                }
                            }
                        },
                    }
                },
            }
        },
        "/api/admin/login": {
            "post": {
                "summary": "Obtain admin token",
                "description": "Authenticate with the admin password to receive a JWT for protected endpoints.",
                "requestBody": {
                    "required": True,
                    "content": {
                        "application/json": {
                            "schema": {
                                "type": "object",
                                "properties": {"password": {"type": "string"}},
                                "required": ["password"],
                            }
                        }
                    },
                },
                "responses": {
                    "200": {
                        "description": "JWT issued.",
                        "content": {
                            "application/json": {
                                "schema": {
                                    "type": "object",
                                    "properties": {"token": {"type": "string"}},
                                }
                            }
                        },
                    },
                    "401": {
                        "description": "Invalid credentials.",
                        "content": {
                            "application/json": {
                                "schema": {
                                    "type": "object",
                                    "properties": {"message": {"type": "string"}},
                                }
                            }
                        },
                    },
                },
            }
        },
        "/api/admin/carousels": {
            "get": {
                "summary": "List carousels",
                "description": "Return the ordered list of carousels with their assigned parties. Requires admin token.",
                "security": [{"bearerAuth": []}],
                "responses": {
                    "200": {
                        "description": "Array of carousels.",
                        "content": {
                            "application/json": {
                                "schema": {
                                    "type": "array",
                                    "items": {"$ref": "#/components/schemas/Carousel"}
                                }
                            }
                        }
                    },
                    "500": {"description": "Error fetching carousels."}
                }
            },
            "post": {
                "summary": "Create a carousel",
                "description": "Create a new carousel at the end of the display order. Requires admin token.",
                "security": [{"bearerAuth": []}],
                "requestBody": {
                    "required": True,
                    "content": {
                        "application/json": {
                            "schema": {
                                "type": "object",
                                "required": ["title"],
                                "properties": {
                                    "title": {"type": "string"},
                                    "partyIds": {
                                        "type": "array",
                                        "items": {"type": "string"},
                                        "description": "Party identifiers to include in the carousel."
                                    }
                                }
                            }
                        }
                    }
                },
                "responses": {
                    "201": {
                        "description": "Carousel created.",
                        "content": {
                            "application/json": {
                                "schema": {"$ref": "#/components/schemas/Carousel"}
                            }
                        }
                    },
                    "400": {"description": "Invalid payload."},
                    "500": {"description": "Error creating carousel."}
                }
            }
        },
        "/api/admin/carousels/{carouselId}": {
            "put": {
                "summary": "Update carousel info",
                "description": "Update carousel metadata such as title or display order. Requires admin token.",
                "security": [{"bearerAuth": []}],
                "parameters": [
                    {
                        "name": "carouselId",
                        "in": "path",
                        "required": True,
                        "schema": {"type": "string"}
                    }
                ],
                "requestBody": {
                    "required": True,
                    "content": {
                        "application/json": {
                            "schema": {
                                "type": "object",
                                "properties": {
                                    "title": {"type": "string"},
                                    "order": {"type": "integer"}
                                }
                            }
                        }
                    }
                },
                "responses": {
                    "200": {
                        "description": "Carousel updated.",
                        "content": {
                            "application/json": {
                                "schema": {
                                    "type": "object",
                                    "properties": {
                                        "message": {"type": "string"},
                                        "carousel": {"$ref": "#/components/schemas/Carousel"}
                                    }
                                }
                            }
                        }
                    },
                    "400": {"description": "Invalid payload."},
                    "404": {"description": "Carousel not found."},
                    "500": {"description": "Error updating carousel."}
                }
            },
            "delete": {
                "summary": "Delete a carousel",
                "description": "Remove a carousel by identifier. Requires admin token.",
                "security": [{"bearerAuth": []}],
                "parameters": [
                    {
                        "name": "carouselId",
                        "in": "path",
                        "required": True,
                        "schema": {"type": "string"}
                    }
                ],
                "responses": {
                    "200": {"description": "Carousel deleted."},
                    "404": {"description": "Carousel not found."},
                    "500": {"description": "Error deleting carousel."}
                }
            }
        },
        "/api/admin/carousels/{carouselId}/parties": {
            "get": {
                "summary": "List carousel parties",
                "description": "Return the parties currently assigned to the carousel in order. Requires admin token.",
                "security": [{"bearerAuth": []}],
                "parameters": [
                    {
                        "name": "carouselId",
                        "in": "path",
                        "required": True,
                        "schema": {"type": "string"}
                    }
                ],
                "responses": {
                    "200": {
                        "description": "Array of party documents.",
                        "content": {
                            "application/json": {
                                "schema": {
                                    "type": "array",
                                    "items": {"$ref": "#/components/schemas/Party"}
                                }
                            }
                        }
                    },
                    "400": {"description": "Invalid carousel id."},
                    "404": {"description": "Carousel not found."},
                    "500": {"description": "Error fetching carousel parties."}
                }
            },
            "put": {
                "summary": "Update carousel parties",
                "description": "Replace the ordered party list for a carousel. Requires admin token.",
                "security": [{"bearerAuth": []}],
                "parameters": [
                    {
                        "name": "carouselId",
                        "in": "path",
                        "required": True,
                        "schema": {"type": "string"}
                    }
                ],
                "requestBody": {
                    "required": True,
                    "content": {
                        "application/json": {
                            "schema": {
                                "type": "object",
                                "required": ["partyIds"],
                                "properties": {
                                    "partyIds": {
                                        "type": "array",
                                        "items": {"type": "string"}
                                    }
                                }
                            }
                        }
                    }
                },
                "responses": {
                    "200": {
                        "description": "Carousel parties updated.",
                        "content": {
                            "application/json": {
                                "schema": {
                                    "type": "object",
                                    "properties": {
                                        "message": {"type": "string"},
                                        "carousel": {"$ref": "#/components/schemas/Carousel"}
                                    }
                                }
                            }
                        }
                    },
                    "400": {"description": "Invalid payload or missing parties."},
                    "404": {"description": "Carousel not found."},
                    "500": {"description": "Error updating carousel parties."}
                }
            }
        },
        "/api/admin/carousels/reorder": {
            "post": {
                "summary": "Reorder carousels",
                "description": "Persist a new display order for the supplied carousel IDs. Requires admin token.",
                "security": [{"bearerAuth": []}],
                "requestBody": {
                    "required": True,
                    "content": {
                        "application/json": {
                            "schema": {
                                "type": "object",
                                "required": ["orderedIds"],
                                "properties": {
                                    "orderedIds": {
                                        "type": "array",
                                        "items": {"type": "string"},
                                        "description": "Carousel IDs in their desired order."
                                    }
                                }
                            }
                        }
                    }
                },
                "responses": {
                    "200": {
                        "description": "Carousels reordered.",
                        "content": {
                            "application/json": {
                                "schema": {
                                    "type": "object",
                                    "properties": {
                                        "message": {"type": "string"}
                                    }
                                }
                            }
                        }
                    },
                    "400": {"description": "Invalid payload or missing items."},
                    "500": {"description": "Error reordering carousels."}
                }
            }
        },
        "/api/admin/sections": {
            "post": {
                "summary": "Create a section",
                "description": "Persist a static section entry for the homepage. Requires admin token.",
                "security": [{"bearerAuth": []}],
                "requestBody": {
                    "required": True,
                    "content": {
                        "application/json": {
                            "schema": {
                                "type": "object",
                                "required": ["title", "content"],
                                "properties": {
                                    "title": {"type": "string"},
                                    "content": {"type": "string"},
                                    "slug": {"type": "string"}
                                }
                            }
                        }
                    }
                },
                "responses": {
                    "201": {
                        "description": "Section created.",
                        "content": {
                            "application/json": {
                                "schema": {"$ref": "#/components/schemas/Section"}
                            }
                        }
                    },
                    "400": {"description": "Invalid payload."},
                    "500": {"description": "Server error while creating the section."}
                }
            }
        },
        "/api/admin/add-party": {
            "post": {
                "summary": "Add a party",
                "description": "Scrape and persist a new party. Requires admin token.",
                "security": [{"bearerAuth": []}],
                "requestBody": {
                    "required": True,
                    "content": {
                        "application/json": {
                            "schema": {
                                "type": "object",
                                "properties": {"url": {"type": "string", "format": "uri"}},
                                "required": ["url"],
                            }
                        }
                    },
                },
                "responses": {
                    "201": {
                        "description": "Party created.",
                        "content": {
                            "application/json": {
                                "schema": {
                                    "type": "object",
                                    "properties": {
                                        "message": {"type": "string"},
                                        "party": {"$ref": "#/components/schemas/Party"},
                                    },
                                }
                            }
                        },
                    },
                    "400": {"description": "Invalid payload."},
                    "409": {"description": "Party already exists."},
                    "500": {"description": "Server error."},
                },
            }
        },
        "/api/admin/clone-party": {
            "post": {
                "summary": "Clone a party",
                "description": "Create a copy of an existing party with a new slug, purchase link, and optional tracking overrides. Requires admin token.",
                "security": [{"bearerAuth": []}],
                "requestBody": {
                    "required": True,
                    "content": {
                        "application/json": {
                            "schema": {"$ref": "#/components/schemas/ClonePartyRequest"}
                        }
                    },
                },
                "responses": {
                    "201": {
                        "description": "Party cloned.",
                        "content": {
                            "application/json": {
                                "schema": {
                                    "type": "object",
                                    "properties": {
                                        "message": {"type": "string"},
                                        "party": {"$ref": "#/components/schemas/Party"},
                                    },
                                }
                            }
                        },
                    },
                    "400": {"description": "Invalid payload or slug."},
                    "404": {"description": "Source party not found."},
                    "409": {"description": "New slug already exists."},
                    "500": {"description": "Server error."},
                },
            }
        },
        "/api/admin/import/carousel-urls": {
            "post": {
                "summary": "Import carousel from explicit URLs",
                "description": "Ensure parties exist for the provided URLs and update the referenced carousel. Requires admin token.",
                "security": [{"bearerAuth": []}],
                "requestBody": {
                    "required": True,
                    "content": {
                        "application/json": {
                            "schema": {"$ref": "#/components/schemas/CarouselUrlImportRequest"}
                        }
                    }
                },
                "responses": {
                    "200": {
                        "description": "Carousel updated from URLs.",
                        "content": {
                            "application/json": {
                                "schema": {
                                    "type": "object",
                                    "properties": {
                                        "message": {"type": "string"},
                                        "carousel": {"$ref": "#/components/schemas/Carousel"},
                                        "addedCount": {"type": "integer"},
                                        "processedUrlCount": {"type": "integer"},
                                        "warnings": {
                                            "type": "array",
                                            "items": {
                                                "type": "object",
                                                "additionalProperties": True,
                                            },
                                        },
                                    },
                                },
                            }
                        },
                    },
                    "400": {"description": "Invalid payload or URLs."},
                    "404": {"description": "Unable to update carousel from provided URLs."}
                },
            }
        },
        "/api/admin/delete-party/{partyId}": {
            "delete": {
                "summary": "Delete a party",
                "description": "Remove an existing party by its identifier. Requires admin token.",
                "security": [{"bearerAuth": []}],
                "parameters": [
                    {
                        "name": "partyId",
                        "in": "path",
                        "required": True,
                        "schema": {"type": "string"},
                        "description": "MongoDB ObjectId of the party to delete.",
                    }
                ],
                "responses": {
                    "200": {"description": "Party deleted."},
                    "404": {"description": "Party not found."},
                    "500": {"description": "Error deleting party."},
                },
            }
        },
        "/api/admin/update-party/{partyId}": {
            "put": {
                "summary": "Update a party",
                "description": "Update select fields on an existing party. Supports editing titles, slugs, images, URLs, timing, descriptions, and location metadata. Requires admin token.",
                "security": [{"bearerAuth": []}],
                "parameters": [
                    {
                        "name": "partyId",
                        "in": "path",
                        "required": True,
                        "schema": {"type": "string"},
                    }
                ],
                "requestBody": {
                    "required": True,
                    "content": {
                        "application/json": {
                            "schema": {"$ref": "#/components/schemas/PartyUpdateRequest"}
                        }
                    },
                },
                "responses": {
                    "200": {"description": "Party updated."},
                    "400": {"description": "Invalid payload."},
                    "404": {"description": "Party not found."},
                    "500": {"description": "Server error."},
                },
            }
        },
    },
    "components": {
        "securitySchemes": {
            "bearerAuth": {
                "type": "http",
                "scheme": "bearer",
                "bearerFormat": "JWT",
            }
        },
        "schemas": {
            "Party": {
                "type": "object",
                "properties": {
                    "_id": {"type": "string"},
                    "name": {"type": "string"},
                    "date": {"type": "string"},
                    "goOutUrl": {"type": "string", "format": "uri"},
                    "originalUrl": {"type": "string", "format": "uri"},
                    "startsAt": {"type": "string", "format": "date-time"},
                    "endsAt": {"type": "string", "format": "date-time"},
                    "city": {"type": "string"},
                    "venue": {"type": "string"},
                    "tags": {"type": "array", "items": {"type": "string"}},
                    "audiences": {"type": "array", "items": {"type": "string"}},
                    "musicGenres": {"type": "array", "items": {"type": "string"}},
                    "areas": {"type": "array", "items": {"type": "string"}},
                    "pixelId": {"type": "string", "nullable": True, "description": "Meta Pixel ID for conversion tracking."},
                },
                "additionalProperties": True,
            },
            "ClonePartyRequest": {
                "type": "object",
                "required": ["sourceSlug", "newSlug", "purchaseLink"],
                "properties": {
                    "sourceSlug": {"type": "string", "description": "Slug of the party to copy from."},
                    "newSlug": {"type": "string", "description": "New unique slug for the cloned party."},
                    "purchaseLink": {"type": "string", "format": "uri", "description": "New purchase URL (replaces original)."},
                    "referralCode": {"type": "string", "nullable": True, "description": "Optional new referral code."},
                    "pixelId": {"type": "string", "nullable": True, "description": "Optional new Meta Pixel ID."},
                },
                "additionalProperties": False,
            },
            "PartyUpdateRequest": {
                "type": "object",
                "description": "Optional fields an admin can edit on a party. Unspecified fields remain unchanged.",
                "properties": {
                    "title": {"type": "string", "description": "Display title; maps to the party name."},
                    "slug": {"type": "string", "description": "Custom slug override used for lookups."},
                    "image": {"type": "string", "format": "uri", "description": "Primary image URL; updates imageUrl and images."},
                    "url": {"type": "string", "format": "uri", "description": "Canonical event URL; also sets originalUrl."},
                    "name": {"type": "string", "description": "Existing name field for backward compatibility."},
                    "imageUrl": {"type": "string", "format": "uri", "description": "Image URL field stored directly on the party."},
                    "date": {"type": "string", "description": "Date value stored alongside startsAt."},
                    "time": {"type": "string", "format": "date-time", "description": "Convenience alias for startsAt/date."},
                    "startsAt": {"type": "string", "format": "date-time", "description": "Event start time in ISO-8601 format."},
                    "endsAt": {"type": "string", "format": "date-time", "description": "Event end time in ISO-8601 format."},
                    "location": {"type": "string", "description": "Freeform location text."},
                    "description": {"type": "string", "description": "Detailed party description."},
                    "region": {"type": "string", "description": "Region or city grouping."},
                    "musicType": {"type": "string", "description": "Music genre or tag."},
                    "eventType": {"type": "string", "description": "Type of event (festival, concert, etc.)."},
                    "age": {"type": "string", "description": "Age restriction text."},
                    "tags": {"type": "array", "items": {"type": "string"}, "description": "Tags applied to the party."},
                    "originalUrl": {"type": "string", "format": "uri", "description": "Source URL of the party."},
                    "canonicalUrl": {"type": "string", "format": "uri", "description": "Normalized canonical URL of the party."},
                    "goOutUrl": {"type": "string", "format": "uri", "description": "Go-Out source URL if applicable."},
                    "referralCode": {"type": "string", "description": "Referral code appended to outbound links."},
                    "pixelId": {"type": "string", "description": "Meta Pixel ID for conversion tracking on this party."},
                },
                "additionalProperties": False,
            },
            "Event": {
                "type": "object",
                "description": "Normalized event payload consumed by listings.",
                "properties": {
                    "id": {"type": "string"},
                    "name": {"type": "string"},
                    "startsAt": {"type": "string", "format": "date-time"},
                    "endsAt": {"type": "string", "format": "date-time"},
                    "canonicalUrl": {"type": "string", "format": "uri"},
                    "purchaseUrl": {"type": "string", "format": "uri"},
                    "originalUrl": {"type": "string", "format": "uri"},
                    "referralCode": {"type": "string"},
                },
                "additionalProperties": True,
            },
            "Dimension": {
                "type": "object",
                "properties": {
                    "slug": {"type": "string"},
                    "name": {"type": "string"},
                    "eventCount": {"type": "integer", "minimum": 0},
                },
                "additionalProperties": True,
            },
            "Tag": {
                "type": "object",
                "properties": {
                    "slug": {"type": "string"},
                    "name": {"type": "string"},
                    "order": {"type": "integer"},
                },
                "required": ["slug", "name"],
            },
            "Carousel": {
                "type": "object",
                "properties": {
                    "id": {"type": "string"},
                    "title": {"type": "string"},
                    "order": {"type": "integer"},
                    "partyIds": {
                        "type": "array",
                        "items": {"type": "string"}
                    }
                },
                "additionalProperties": True,
            },
            "Section": {
                "type": "object",
                "properties": {
                    "_id": {"type": "string"},
                    "title": {"type": "string"},
                    "content": {"type": "string"},
                    "slug": {"type": "string"},
                    "order": {"type": "integer"},
                    "createdAt": {"type": "string", "format": "date-time"},
                    "updatedAt": {"type": "string", "format": "date-time"}
                },
                "additionalProperties": True,
            },
            "AnalyticsVisitorRequest": {
                "type": "object",
                "properties": {
                    "sessionId": {"type": "string"}
                },
                "required": ["sessionId"],
                "additionalProperties": False,
            },
            "PartyAnalyticsRequest": {
                "type": "object",
                "description": "Identify a party by ID or slug to increment analytics counters.",
                "properties": {
                    "partyId": {"type": "string"},
                    "partySlug": {"type": "string"},
                },
                "additionalProperties": False,
            },
            "PartyAnalyticsEntry": {
                "type": "object",
                "properties": {
                    "partyId": {"type": "string"},
                    "slug": {"type": "string"},
                    "name": {"type": "string"},
                    "date": {"type": "string"},
                    "views": {"type": "integer", "minimum": 0},
                    "redirects": {"type": "integer", "minimum": 0},
                },
                "required": ["partyId", "views", "redirects"],
                "additionalProperties": True,
            },
            "AnalyticsSummary": {
                "type": "object",
                "properties": {
                    "generatedAt": {"type": "string", "format": "date-time"},
                    "uniqueVisitors24h": {"type": "integer", "minimum": 0},
                    "parties": {
                        "type": "array",
                        "items": {"$ref": "#/components/schemas/PartyAnalyticsEntry"},
                    },
                },
                "required": ["generatedAt", "uniqueVisitors24h", "parties"],
            },
            "CarouselUrlImportRequest": {
                "type": "object",
                "required": ["carouselName", "urls"],
                "properties": {
                    "carouselName": {"type": "string"},
                    "urls": {
                        "type": "array",
                        "items": {"type": "string", "format": "uri"},
                        "minItems": 1,
                    },
                    "referral": {"type": "string"},
                },
                "additionalProperties": False,
            },
        },
    },
}


def build_openapi_document():
    """Generate the OpenAPI document, hydrating runtime server information."""
    document = copy.deepcopy(OPENAPI_TEMPLATE)
    server_url = (request.host_url or "").rstrip("/")
    if not server_url:
        server_url = "http://localhost"
    document["servers"] = [{"url": server_url}]
    return document


@app.route("/openapi.json", methods=["GET"])
def openapi_json():
    """Expose the OpenAPI definition for API consumers."""
    return jsonify(build_openapi_document()), 200


@app.route("/docs", methods=["GET"])
def docs_page():
    """Render Swagger UI backed by the generated OpenAPI definition."""
    spec_url = url_for("openapi_json", _external=True)
    html = f"""<!doctype html>
<html lang=\"en\">
  <head>
    <meta charset=\"utf-8\">
    <title>Parties247 API Documentation</title>
    <meta name=\"viewport\" content=\"width=device-width, initial-scale=1\">
    <link rel=\"stylesheet\" href=\"https://cdnjs.cloudflare.com/ajax/libs/swagger-ui/5.10.5/swagger-ui.min.css\" crossorigin=\"anonymous\" />
    <style>
      body {{ margin: 0; background-color: #f5f5f5; }}
      #swagger-ui {{ box-shadow: none; }}
    </style>
  </head>
  <body>
    <div id=\"swagger-ui\"></div>
    <noscript>
      <p>JavaScript is required to view the interactive documentation. Download the <a href=\"{spec_url}\">OpenAPI JSON</a>.</p>
    </noscript>
    <script src=\"https://cdnjs.cloudflare.com/ajax/libs/swagger-ui/5.10.5/swagger-ui-bundle.min.js\" crossorigin=\"anonymous\"></script>
    <script src=\"https://cdnjs.cloudflare.com/ajax/libs/swagger-ui/5.10.5/swagger-ui-standalone-preset.min.js\" crossorigin=\"anonymous\"></script>
    <script>
      window.onload = () => {{
        SwaggerUIBundle({{
          url: "{spec_url}",
          dom_id: '#swagger-ui',
          presets: [SwaggerUIBundle.presets.apis, SwaggerUIStandalonePreset],
          layout: 'BaseLayout'
        }});
      }};
    </script>
  </body>
</html>"""
    return html, 200, {"Content-Type": "text/html; charset=utf-8"}


@app.route("/api/admin/login", methods=["POST"])
def admin_login():
    data = request.get_json(silent=True) or {}
    password = (data.get("password") or "").encode()
    if not ADMIN_HASH or not JWT_SECRET:
        app.logger.error("Admin credentials or JWT secret missing; refusing login attempt.")
        return jsonify({"message": "Server misconfigured."}), 500
    try:
        hashed_attempt = bcrypt.hashpw(password, ADMIN_HASH)
        if hmac.compare_digest(hashed_attempt, ADMIN_HASH):
            exp = datetime.utcnow() + timedelta(minutes=15)
            token = jwt.encode({"exp": exp}, JWT_SECRET, algorithm="HS256")
            if isinstance(token, bytes):
                token = token.decode()
            return jsonify({"token": token}), 200
    except ValueError:
        pass
    return jsonify({"message": "Invalid credentials."}), 401

# --- Tag helpers + schemas ---
def slugify_tag(name: str) -> str:
    return "-".join((name or "").strip().lower().split())

def ensure_tags_seeded():
    """Backfill tags collection from parties if empty."""
    if tags_collection.count_documents({}) == 0:
        distinct_tags = [t for t in (parties_collection.distinct("tags") or []) if isinstance(t, str) and t.strip()]
        ops = []
        for idx, t in enumerate(sorted(set(distinct_tags), key=lambda x: x.lower())):
            ops.append(tags_collection.update_one(
                {"slug": slugify_tag(t)},
                {"$setOnInsert": {"slug": slugify_tag(t), "name": t, "order": idx}},
                upsert=True
            ))
        if ops:
            tags_collection.bulk_write(ops)

class TagOrderRequest(BaseModel):
    slug: str
    newIndex: int
    class Config:
        extra = "forbid"

class TagRenameRequest(BaseModel):
    oldName: str
    newName: str
    class Config:
        extra = "forbid"

# --- Referral schemas ---
class ReferralUpdateSchema(BaseModel):
    code: str
    class Config:
        extra = "forbid"


class AnalyticsVisitorRequest(BaseModel):
    sessionId: str
    pageUrl: str | None = None
    referrer: str | None = None
    utmSource: str | None = None
    utmMedium: str | None = None
    utmCampaign: str | None = None
    utmTerm: str | None = None
    utmContent: str | None = None
    screenWidth: int | None = None
    screenHeight: int | None = None
    language: str | None = None
    timezone: str | None = None

    class Config:
        extra = "forbid"


class PartyAnalyticsRequest(BaseModel):
    partyId: str | None = None
    partySlug: str | None = None
    sessionId: str | None = None
    referrer: str | None = None

    class Config:
        extra = "forbid"

# --- Parties schemas ---
class AddPartyRequest(BaseModel):
    url: str
    carouselName: str | None = None

    class Config:
        extra = "forbid"

class ClonePartyRequest(BaseModel):
    sourceSlug: str
    newSlug: str
    purchaseLink: str
    referralCode: str | None = None
    pixelId: str | None = None

    class Config:
        extra = "forbid"

class PartyUpdateSchema(BaseModel):
    title: str | None = None
    slug: str | None = None
    image: str | None = None
    url: str | None = None
    name: str | None = None
    imageUrl: str | None = None
    date: str | None = None
    time: str | None = None
    startsAt: str | None = None
    endsAt: str | None = None
    location: str | None = None
    description: str | None = None
    region: str | None = None
    musicType: str | None = None
    eventType: str | None = None
    age: str | None = None
    tags: list[str] | None = None
    originalUrl: str | None = None
    canonicalUrl: str | None = None
    goOutUrl: str | None = None
    goOutUrl: str | None = None
    referralCode: str | None = None
    pixelId: str | None = None
    ticketPrice: float | None = None
    class Config:
        extra = "forbid"


# --- Carousel schemas ---
class CarouselCreateSchema(BaseModel):
    title: str
    partyIds: list[str] = []
    class Config:
        extra = "forbid"

class CarouselUpdateSchema(BaseModel):
    title: str | None = None
    order: int | None = None
    class Config:
        extra = "forbid"


class CarouselPartiesUpdateSchema(BaseModel):
    partyIds: list[str]
    class Config:
        extra = "forbid"

class CarouselReorderSchema(BaseModel):
    orderedIds: list[str]
    class Config:
        extra = "forbid"


class CarouselUrlListImportSchema(BaseModel):
    carouselName: str
    urls: list[str]
    referral: str | None = None

    class Config:
        extra = "forbid"


class SectionCreateSchema(BaseModel):
    title: str
    content: str
    slug: str | None = None

    class Config:
        extra = "forbid"


class SectionUpdateSchema(BaseModel):
    title: str | None = None
    content: str | None = None
    slug: str | None = None

    class Config:
        extra = "forbid"


class SectionReorderSchema(BaseModel):
    orderedIds: list[str]

    class Config:
        extra = "forbid"

# --- Classification helpers ---
def get_region(location: str) -> str:
    south_keywords = [" ", "", "", "", ""]
    north_keywords = ["", "", "", "", "", ""]
    center_keywords = [" ", "", " ", "", "", "", "-", "tlv"]
    loc = (location or "").lower()
    if any(k in loc for k in south_keywords):
        return ""
    if any(k in loc for k in north_keywords):
        return ""
    if any(k in loc for k in center_keywords):
        return ""
    return " "

def get_music_type(text: str) -> str:
    techno_keywords = ["", "techno", "after", "", "house", "", "electronic", ""]
    trance_keywords = ["", "trance", "", "psy-trance", "psytrance"]
    mainstream_keywords = ["", "mainstream", " ", "hip hop", "", "reggaeton", "pop", ""]
    txt = (text or "").lower()
    if any(k in txt for k in techno_keywords):
        return ""
    if any(k in txt for k in trance_keywords):
        return ""
    if any(k in txt for k in mainstream_keywords):
        return ""
    return ""

def get_event_type(text: str) -> str:
    festival_keywords = ["", "festival"]
    nature_keywords = ["", "nature", "", "forest", "", "beach", "open air", ""]
    club_keywords = ["", "club", "", "", " 17", "gagarin", "block", "haoman 17", "rooftop", ""]
    txt = (text or "").lower()
    if any(k in txt for k in festival_keywords):
        return ""
    if any(k in txt for k in nature_keywords):
        return " "
    if any(k in txt for k in club_keywords):
        return " "
    return ""

def get_age(text: str, minimum_age: int) -> str:
    if minimum_age >= 21:
        return "21+"
    if minimum_age >= 18:
        return "18+"
    if "" in (text or "").lower():
        return ""
    if minimum_age > 0:
        return "18+"
    return " "

def get_tags(text: str, location: str) -> list:
    tags = []
    tag_map = {
        " ": [" ", "free alcohol", " ", "free bar"],
        "": ["open air", "", "", "", "", "rooftop", ""],
        "": ["", "eilat"],
        " ": [" ", "tel aviv", "tlv"],
    }
    combined_text = f"{text or ''} {location or ''}".lower()
    for tag, keywords in tag_map.items():
        if any(keyword in combined_text for keyword in keywords):
            tags.append(tag)
    return list(set(tags))

def _extract_price_from_schema_org(schema_org) -> float | None:
    """
    Parse the schemaOrg FAQPage from go-out.co __NEXT_DATA__ to extract the
    final ticket price (including service fee).
    FAQ answer contains e.g. " -86.80 (   )"
    """
    if not schema_org:
        return None
    faq_items = schema_org if isinstance(schema_org, list) else [schema_org]
    for faq_item in faq_items:
        if not faq_item or faq_item.get("@type") != "FAQPage":
            continue
        for question in faq_item.get("mainEntity", []):
            answer_text = question.get("acceptedAnswer", {}).get("text", "")
            m = re.search(r"([\d]+\.?\d*)", answer_text)
            if m:
                return round(float(m.group(1)), 2)
    return None

# --- Scraper ---
def scrape_party_details(url: str):
    if not is_url_allowed(url):
        raise ValueError("URL is not allowed.")
    app.logger.info(f"[SCRAPER] start {url}")
    try:
        headers = {"User-Agent": "Mozilla/5.0"}
        response = requests.get(url, headers=headers, timeout=15)
        app.logger.info(f"[SCRAPER] status {response.status_code}")
        response.raise_for_status()

        soup = BeautifulSoup(response.text, "html.parser")
        script_tag = soup.find("script", {"id": "__NEXT_DATA__"})
        if not script_tag:
            raise ValueError("Could not find party data script (__NEXT_DATA__).")

        json_data = json.loads(script_tag.string)
        event_data = json_data.get("props", {}).get("pageProps", {}).get("event")
        if not event_data:
            raise ValueError("Event data not in expected format inside JSON.")

        image_path = ""
        if event_data.get("CoverImage") and event_data["CoverImage"].get("Url"):
            image_path = event_data["CoverImage"]["Url"]
        elif event_data.get("WhatsappImage") and event_data["WhatsappImage"].get("Url"):
            image_path = event_data["WhatsappImage"]["Url"]

        if image_path:
            cover_image_path = image_path.replace("_whatsappImage.jpg", "_coverImage.jpg")
            image_url = f"https://d15q6k8l9pfut7.cloudfront.net/{cover_image_path}"
        else:
            og_image_tag = soup.find("meta", {"property": "og:image"})
            og_image_url = og_image_tag["content"] if og_image_tag else ""
            if og_image_url:
                image_url = og_image_url.replace("_whatsappImage.jpg", "_coverImage.jpg")
            else:
                raise ValueError("Could not find party image URL.")

        description = event_data.get("Description", "")
        cleaned_desc = " ".join(list(filter(None, description.split("\n")))[:3]).strip()
        if len(cleaned_desc) > 250:
            cleaned_desc = cleaned_desc[:247] + "..."

        full_text = f"{event_data.get('Title', '')} {description}"
        location = event_data.get("Adress", "")
        classification = classify_party_data(
            title=event_data.get("Title", ""),
            description=description,
            location=location
        )
        canonical = normalize_url(url)
        go_out = normalized_or_none_for_dedupe(url)

        party_details = {
            "name": event_data.get("Title"),
            "imageUrl": image_url,
            "date": event_data.get("StartingDate"),
            "location": location,
            "description": cleaned_desc or "No description available.",
            "region": get_region(location),
            "musicType": get_music_type(full_text),
            "eventType": get_event_type(full_text),
            "age": get_age(full_text, event_data.get("MinimumAge", 0)),
            "tags": get_tags(full_text, location),
            "audiences": classification["audiences"],
            "musicGenres": classification["musicGenres"],
            "areas": classification["areas"],
            "originalUrl": url,
            "canonicalUrl": canonical,
            "ticketPrice": None,
        }

        # Extract ticket price from schemaOrg FAQ  contains the final price including service fee
        # e.g. " -86.80 (   )"
        ticket_price = _extract_price_from_schema_org(event_data.get("schemaOrg"))
        party_details["ticketPrice"] = ticket_price

        if go_out:
            party_details["goOutUrl"] = go_out

        if not all([party_details["name"], party_details["date"], party_details["location"]]):
            raise ValueError("Scraped data is missing critical fields.")
        return party_details

    except requests.exceptions.RequestException as e:
        app.logger.error(f"[SCRAPER] HTTP error: {e}")
        raise
    except Exception as e:
        app.logger.error(f"[SCRAPER] error: {e}")
        raise

def scrape_ticket_price_only(url: str) -> int | None:
    if not is_url_allowed(url):
        return None
    try:
        headers = {
            "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36",
            "Accept": "text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,*/*;q=0.8",
            "Accept-Language": "he-IL,he;q=0.9,en-US;q=0.8,en;q=0.7",
        }
        response = requests.get(url, headers=headers, timeout=15)
        # Force UTF-8 encoding for Hebrew content if not automatically detected correctly
        if response.encoding and response.encoding.lower() not in ('utf-8', 'utf8'):
             response.encoding = 'utf-8'
             
        # Parse TicketTypes from __NEXT_DATA__ (most reliable source  always present,
        # handles multiple ticket tiers, includes service fee)
        try:
            soup = BeautifulSoup(response.text, "html.parser")
            script_tag = soup.find("script", {"id": "__NEXT_DATA__"})
            if script_tag and script_tag.string:
                json_data = json.loads(script_tag.string)
                event_data = json_data.get("props", {}).get("pageProps", {}).get("event", {})
                price = _extract_price_from_schema_org(event_data.get("schemaOrg"))
                if price is not None:
                    return price
        except Exception:
            pass

    except Exception as e:
        app.logger.warning(f"[PRICE SCAN] Error fetching {url}: {e}")
    return None

@scheduler.task("cron", id="daily_price_scan", hour=0)
def scheduled_price_scan():
    with app.app_context():
        app.logger.info("[PRICE SCAN] Starting daily price scan...")
        now = datetime.now(timezone.utc)
        cutoff = now - timedelta(days=1)
        
        # Determine "active" parties by checking if they are not significantly in the past
        # Since 'date' might be string, we iterate and check. 
        # For efficiency, we can limit to parties created/updated recently or just scan all since dataset isn't huge.
        cursor = parties_collection.find({})
        count = 0
        updated = 0
            
        for party in cursor:
            try:
                p_date_val = party.get("date") or party.get("startsAt")
                p_date = parse_datetime(p_date_val)
                
                # If party is more than 24h old (past), skip update
                if p_date and p_date < cutoff:
                    continue
                
                url = party.get("originalUrl") or party.get("goOutUrl")
                if not url:
                    continue

                new_price = scrape_ticket_price_only(url)
                
                # Update if price is found and different (or if it was missing)
                # Note: If new_price is None, we DO NOT clear the existing price, as scraping might fail temporarily.
                old_price = party.get("ticketPrice")
                
                if new_price is not None and new_price != old_price:
                    parties_collection.update_one(
                        {"_id": party["_id"]},
                        {"$set": {"ticketPrice": new_price}}
                    )
                    updated += 1
                count += 1
            except Exception as e:
                app.logger.error(f"[PRICE SCAN] Error processing party {party.get('_id')}: {e}")
                continue
                
        app.logger.info(f"[PRICE SCAN] Completed. Checked {count} parties, updated {updated}.")
        return {"checked": count, "updated": updated}

@app.route("/api/admin/update-prices", methods=["POST"])
@protect
def manual_price_scan():
    try:
        # Run in background to avoid timeout? Or just run it. 
        # It's lightweight so it should be fine, but if there are many parties, it might timeout.
        # Let's run it directly for now as requested "scan all parties".
        # If the user has many parties, we might want to thread it.
        # But given the user said "only price so it wont be a long process", we assume it's fast enough.
        # We'll just call the function.
        result = scheduled_price_scan() 
        return jsonify({"message": "Price scan completed.", "details": result}), 200
    except Exception as e:
        return jsonify({"message": "Error running price scan", "error": str(e)}), 500

# --- Routes ---

# Static generation data APIs


def event_related_paths(event: dict) -> list[str]:
    paths = {f"/event/{event.get('slug') or ''}"}
    city_slug = event.get("city", {}).get("slug")
    if city_slug:
        paths.add(f"/city/{city_slug}")
    venue_slug = event.get("venue", {}).get("slug")
    if venue_slug:
        paths.add(f"/venue/{venue_slug}")
    for genre in event.get("genres", []):
        if genre.get("slug"):
            paths.add(f"/genre/{genre['slug']}")
    if event.get("startsAt"):
        day = event["startsAt"].split("T", 1)[0]
        paths.add(f"/date/{day}")
    return sorted(paths)


@app.route("/api/events", methods=["GET"])
@limiter.limit("100 per minute")
def list_events_api():
    events = serialize_events(include_past=True)
    payload = {
        "generatedAt": isoformat_or_none(datetime.utcnow().replace(tzinfo=timezone.utc)),
        "items": events,
    }
    return json_response(payload, cache_seconds=EVENT_CACHE_SECONDS)


@app.route("/api/events/<slug>", methods=["GET"])
@limiter.limit("100 per minute")
def event_detail_api(slug: str):
    event, original = find_event_by_slug(slug)
    if not event:
        return jsonify({"message": "Event not found."}), 404

    updated, reason = persist_party_metric(original, "views") if original else (False, None)
    if not updated and reason not in {None, "archived", "unavailable"}:
        app.logger.warning(
            f"Failed to increment view counter for event '{slug}': reason={reason}"
        )

    referral = default_referral_code()
    original_copy = dict(original or {})
    apply_default_referral(original_copy, referral)

    purchase_url = (
        original_copy.get("goOutUrl")
        or original_copy.get("originalUrl")
        or original_copy.get("canonicalUrl")
    )

    event_payload = dict(event)
    if purchase_url:
        event_payload["purchaseUrl"] = purchase_url
    original_url = original_copy.get("originalUrl")
    if original_url:
        event_payload["originalUrl"] = original_url
    referral_code = original_copy.get("referralCode")
    if referral_code:
        event_payload["referralCode"] = referral_code

    payload = {
        "generatedAt": isoformat_or_none(datetime.utcnow().replace(tzinfo=timezone.utc)),
        "event": event_payload,
    }
    return json_response(payload, cache_seconds=EVENT_CACHE_SECONDS)


@app.route("/api/cities", methods=["GET"])
@limiter.limit("100 per minute")
def list_cities_api():
    events = serialize_events(include_past=False)
    items = [item for item in aggregate_dimension(events, "city") if item.get("eventCount")]
    payload = {
        "generatedAt": isoformat_or_none(datetime.utcnow().replace(tzinfo=timezone.utc)),
        "items": items,
    }
    return json_response(payload, cache_seconds=LIST_CACHE_SECONDS)


@app.route("/api/venues", methods=["GET"])
@limiter.limit("100 per minute")
def list_venues_api():
    events = serialize_events(include_past=False)
    items = [item for item in aggregate_dimension(events, "venue") if item.get("eventCount")]
    payload = {
        "generatedAt": isoformat_or_none(datetime.utcnow().replace(tzinfo=timezone.utc)),
        "items": items,
    }
    return json_response(payload, cache_seconds=LIST_CACHE_SECONDS)


@app.route("/api/genres", methods=["GET"])
@limiter.limit("100 per minute")
def list_genres_api():
    events = serialize_events(include_past=False)
    items = [item for item in aggregate_genres(events) if item.get("eventCount")]
    payload = {
        "generatedAt": isoformat_or_none(datetime.utcnow().replace(tzinfo=timezone.utc)),
        "items": items,
    }
    return json_response(payload, cache_seconds=LIST_CACHE_SECONDS)


# Parties
@app.route("/api/admin/add-party", methods=["POST"])
@limiter.limit("100 per minute")
@protect
def add_party():
    payload = request.get_json(silent=True) or {}
    try:
        req = AddPartyRequest(**payload)
    except ValidationError as ve:
        app.logger.warning(f"[VALIDATION] {ve}")
        return jsonify({"message": "Invalid request", "errors": ve.errors()}), 400
    url = req.url
    if not is_url_allowed(url):
        return jsonify({"message": "URL is not allowed."}), 400
    try:
        party_data = scrape_party_details(url)
        referral = default_referral_code()
        apply_default_referral(party_data, referral)
        party_data.setdefault("slug", slugify_value(party_data.get("name")))
        canonical = party_data["canonicalUrl"]
        res = parties_collection.update_one(
            {"$or": [{"canonicalUrl": canonical}, {"goOutUrl": canonical}]},
            {"$setOnInsert": party_data},
            upsert=True,
        )
        carousel_info = None
        added_to_carousel = False
        if res.matched_count == 1 and res.upserted_id is None:
            doc = parties_collection.find_one(
                {"$or": [{"canonicalUrl": canonical}, {"goOutUrl": canonical}]},
                {"_id": 1}
            )
            if doc and req.carouselName:
                carousel_doc, added = ensure_carousel_contains_party(req.carouselName, doc.get("_id"))
                if carousel_doc:
                    carousel_info = serialize_carousel(carousel_doc)
                added_to_carousel = added
                response_payload = {
                    "message": "Party already existed.",
                    "id": str(doc.get("_id")),
                    "addedToCarousel": added_to_carousel,
                }
                if carousel_info:
                    response_payload["carousel"] = carousel_info
                return jsonify(response_payload), 200
            return jsonify({"message": "This party has already been added.", "id": str(doc["_id"])}), 409
        party_data["_id"] = str(res.upserted_id)
        event_view = normalize_event(party_data)
        notify_indexers([event_view.get("canonicalUrl")])
        trigger_revalidation(event_related_paths(event_view))
        if req.carouselName:
            carousel_doc, added_to_carousel = ensure_carousel_contains_party(req.carouselName, party_data.get("_id"))
            if carousel_doc:
                carousel_info = serialize_carousel(carousel_doc)
        response_payload = {
            "message": "Party added successfully!",
            "party": party_data,
        }
        if carousel_info:
            response_payload["carousel"] = carousel_info
            response_payload["addedToCarousel"] = added_to_carousel
        return jsonify(response_payload), 201
    except errors.DuplicateKeyError as e:
        app.logger.warning(f"[DB] DuplicateKeyError: {getattr(e, 'details', None)}")
        return jsonify({"message": "This party has already been added."}), 409
        app.logger.error(f"[DB] {str(e)}")
        return jsonify({"message": f"An error occurred: {str(e)}"}), 500

@app.route("/api/admin/clone-party", methods=["POST"])
@limiter.limit("20 per minute")
@protect
def clone_party():
    payload = request.get_json(silent=True) or {}
    try:
        req = ClonePartyRequest(**payload)
    except ValidationError as ve:
        app.logger.warning(f"[VALIDATION] {ve}")
        return jsonify({"message": "Invalid request", "errors": ve.errors()}), 400

    new_slug = slugify_value(req.newSlug)
    if not new_slug:
        return jsonify({"message": "Invalid new slug."}), 400

    if parties_collection.find_one({"slug": new_slug}):
         return jsonify({"message": "New slug already exists."}), 409

    _, source_doc = find_event_by_slug(req.sourceSlug)
    if not source_doc:
         return jsonify({"message": "Source party not found."}), 404

    new_party = copy.deepcopy(source_doc)
    new_party.pop("_id", None)
    
    new_party["slug"] = new_slug
    new_party["slugOverride"] = new_slug
    
    canonical = normalize_url(req.purchaseLink)
    new_party["originalUrl"] = req.purchaseLink
    new_party["canonicalUrl"] = canonical
    new_party["goOutUrl"] = canonical

    if req.referralCode is not None:
        new_party["referralCode"] = req.referralCode
    
    if req.pixelId is not None:
        new_party["pixelId"] = req.pixelId
    
    # Update title/name based on slug? 
    # Usually better to keep original name or maybe user wants to change it later.
    # The request doesn't include name change.
    
    try:
         res = parties_collection.insert_one(new_party)
         new_party["_id"] = str(res.inserted_id)
         
         event_view = normalize_event(new_party)
         notify_indexers([event_view.get("canonicalUrl")])
         trigger_revalidation(event_related_paths(event_view))
         
         return jsonify({
            "message": "Party cloned successfully!",
            "party": normalize_event(new_party)
         }), 201
    except Exception as e:
        app.logger.error(f"[DB] {str(e)}")
        return jsonify({"message": f"An error occurred: {str(e)}"}), 500

@app.route("/api/admin/delete-party/<party_id>", methods=["DELETE"])
@limiter.limit("100 per minute")
@protect
def delete_party(party_id):
    try:
        obj_id = ObjectId(party_id)
        existing = parties_collection.find_one({"_id": obj_id}) or {}
        result = parties_collection.delete_one({"_id": obj_id})
        if result.deleted_count == 0:
            return jsonify({"message": "Party not found."}), 404
        event_view = normalize_event(existing)
        notify_indexers([event_view.get("canonicalUrl")])
        trigger_revalidation(event_related_paths(event_view))
        return jsonify({"message": "Party deleted successfully!"}), 200
    except Exception as e:
        return jsonify({"message": "Error deleting party", "error": str(e)}), 500

@app.route("/api/admin/update-party/<party_id>", methods=["PUT"])
@limiter.limit("100 per minute")
@protect
def update_party(party_id):
    try:
        payload = request.get_json(silent=True) or {}
        obj_id = ObjectId(party_id)
        update = PartyUpdateSchema(**payload)
        data = update.dict(exclude_unset=True)

        if "title" in data:
            data.setdefault("name", data.pop("title"))

        if "slug" in data:
            slug_value = data.pop("slug")
            if slug_value is not None:
                data["slugOverride"] = slug_value
                data.setdefault("slug", slug_value)

        if "image" in data:
            image_value = data.pop("image")
            if image_value is not None:
                data["imageUrl"] = image_value
                data["images"] = [image_value]

        if "url" in data:
            url_value = data.pop("url")
            if url_value is not None:
                data["canonicalUrl"] = url_value
                data.setdefault("originalUrl", url_value)

        if "time" in data:
            time_value = data.pop("time")
            if time_value is not None:
                data["startsAt"] = time_value
                data["date"] = time_value

        if data.get("startsAt") and not data.get("date"):
            data["date"] = data["startsAt"]
        if not data:
            return jsonify({"message": "No valid fields provided."}), 400
        result = parties_collection.update_one({"_id": obj_id}, {"$set": data})
        if result.matched_count == 0:
            return jsonify({"message": "Party not found."}), 404
        updated_doc = parties_collection.find_one({"_id": obj_id}) or {}
        event_view = normalize_event(updated_doc)
        notify_indexers([event_view.get("canonicalUrl")])
        trigger_revalidation(event_related_paths(event_view))
        return jsonify({"message": "Party updated successfully!"}), 200
    except ValidationError as ve:
        app.logger.warning(f"[VALIDATION] {ve}")
        return jsonify({"message": "Invalid party data", "errors": ve.errors()}), 400
    except Exception as e:
        app.logger.error(f"Error updating party {party_id}: {e}")
        return jsonify({"message": "An error occurred", "error": str(e)}), 500

@app.route("/api/parties", methods=["GET"])
@limiter.limit("100 per minute")
def get_parties():
    try:
        items = []
        referral = default_referral_code()
        now = datetime.now(timezone.utc)
        yesterday_date = (now - timedelta(days=1)).date()
        cleanup_cutoff = now - timedelta(days=30)
        try:
            date_param = request.args.get("date")
            upcoming_param = request.args.get("upcoming")
            
            audience_filter = request.args.get("audience") # e.g. ?audience=18+
            genre_filter = request.args.get("genre")       # e.g. ?genre=techno
            area_filter = request.args.get("area")         # e.g. ?area=haifa
        except Exception:
            date_param = None
            upcoming_param = None
            audience_filter = None
            genre_filter = None
            area_filter = None
        filter_date = None
        upcoming_only = False
        query = {}
        
        # Existing Date Logic (simplified for query construction)
        # Note: We usually filter dates in python loop in your code because of complex parsing,
        # but strictly speaking, filters like genres/areas are best done in Mongo query.
        
        if audience_filter:
            query["audiences"] = audience_filter
        if genre_filter:
            query["musicGenres"] = genre_filter
        if area_filter:
            query["areas"] = area_filter

        # Fetch with query
        cursor = parties_collection.find(query).sort("date", 1)

        # Iterate and apply Python-side Date logic (Cleaning/Upcoming/Date Match)
        for party in cursor:
            # [Existing Date Logic from your code]
            party_id = party.get("_id")
            event_date = parse_datetime(party.get("date") or party.get("startsAt"))
            
            # 1. Cleanup old events
            if event_date:
                event_date = event_date.astimezone(timezone.utc)
                if event_date <= cleanup_cutoff:
                    if party_id:
                        parties_collection.delete_one({"_id": party_id})
                    continue
                
                # 2. Filter specific Date (Python side)
                if date_param:
                    parsed_filter = parse_datetime(date_param)
                    if parsed_filter and event_date.date() != parsed_filter.date():
                        continue
                        
                # 3. Filter Upcoming (Python side)
                # Note: your code defined yesterday_date, make sure it's defined
                yesterday_date = (now - timedelta(days=1)).date()
                if upcoming_param:
                     is_upcoming = str(upcoming_param).lower() in {"1", "true", "yes", "on"}
                     if is_upcoming and event_date.date() < now.date():
                         continue
                
                if event_date.date() == yesterday_date:
                    continue
            else:
                # If no date, and filtering by date/upcoming, skip
                if date_param or upcoming_param:
                    continue

            # Serialize
            party["_id"] = str(party["_id"])
            slug = party.get("slug")
            if not slug:
                 # [Slug generation logic]
                 slug = slugify_value(party.get("name")) # Simplified for brevity
            party["slug"] = slug or ""
            apply_default_referral(party, referral)
            items.append(party)

        return jsonify(items), 200
    except Exception as e:
        app.logger.error(f"Error fetching parties: {e}")
        return jsonify({"message": "Error fetching parties", "error": str(e)}), 500

# --- Carousels ---


def serialize_carousel(doc: dict) -> dict:
    data = dict(doc or {})
    raw_id = data.pop("_id", None)
    if raw_id is not None:
        data["id"] = str(raw_id)
    elif "id" in data and data["id"] is not None:
        data["id"] = str(data["id"])
    party_ids = []
    for pid in data.get("partyIds", []):
        if isinstance(pid, ObjectId):
            party_ids.append(str(pid))
        elif isinstance(pid, str):
            party_ids.append(pid)
    data["partyIds"] = party_ids
    return data


def _is_go_out_tickets_url(url: str) -> bool:
    try:
        parsed = urlparse((url or "").strip())
    except Exception:
        return False
    if parsed.scheme not in ("http", "https"):
        return False
    host = parsed.netloc.lower()
    if not host.endswith("go-out.co"):
        return False
    path = parsed.path or ""
    return path.startswith(GO_OUT_TICKETS_PREFIX)


def _lookup_case_insensitive(source: dict, *candidates: str):
    if not isinstance(source, dict):
        return None
    lower_map = {str(key).lower(): key for key in source.keys()}
    for name in candidates:
        if name in source:
            return source[name]
        key = lower_map.get(str(name).lower())
        if key is not None:
            return source[key]
    return None


def _sanitize_ticket_payload(raw: dict) -> dict | None:
    if not isinstance(raw, dict):
        return None
    types = _lookup_case_insensitive(raw, "Types")
    if not isinstance(types, list):
        return None
    normalized_types = []
    for item in types:
        text = str(item).strip()
        if text:
            normalized_types.append(text)
    if not normalized_types:
        return None

    skip_raw = _lookup_case_insensitive(raw, "skip")
    limit_raw = _lookup_case_insensitive(raw, "limit")
    has_range = skip_raw is not None or limit_raw is not None
    if not has_range:
        return None

    try:
        skip_val = int(skip_raw)
    except Exception:
        skip_val = 0
    try:
        limit_val = int(limit_raw)
    except Exception:
        limit_val = 20
    if skip_val < 0:
        skip_val = 0
    if limit_val <= 0:
        limit_val = 20

    location = _lookup_case_insensitive(raw, "location")
    location_text = str(location).strip() if isinstance(location, str) else None
    if not location_text:
        location_text = "IL"

    recived_raw = _lookup_case_insensitive(raw, "recivedDate", "receivedDate", "recievedDate")
    recived_text = None
    if isinstance(recived_raw, str) and recived_raw.strip():
        recived_text = recived_raw.strip()
    else:
        parsed = parse_datetime(recived_raw)
        if parsed:
            recived_text = parsed.astimezone(timezone.utc).isoformat().replace("+00:00", "Z")
    if not recived_text:
        recived_text = datetime.utcnow().replace(tzinfo=timezone.utc).isoformat().replace("+00:00", "Z")

    payload = {
        "skip": skip_val,
        "limit": limit_val,
        "location": location_text,
        "Types": normalized_types,
        "recivedDate": recived_text,
    }
    return payload


def _extract_ticket_category_payload(next_data: dict) -> dict | None:
    candidates: list[dict] = []

    def _walk(node):
        if isinstance(node, dict):
            payload = _sanitize_ticket_payload(node)
            if payload:
                candidates.append(payload)
            for value in node.values():
                _walk(value)
        elif isinstance(node, list):
            for item in node:
                _walk(item)

    _walk(next_data or {})
    if not candidates:
        return None
    return candidates[0]


def _extract_event_slug_from_ticket_item(item: dict) -> str | None:
    if not isinstance(item, dict):
        return None
    for key in ("Url", "url", "slug", "Slug", "_id", "id"):
        if key in item:
            value = item.get(key)
            if isinstance(value, (int, float)):
                value = str(int(value))
            elif value is None:
                continue
            text = str(value).strip()
            if text:
                if "/" in text:
                    parsed = urlparse(text)
                    if parsed.path and "/event/" in parsed.path:
                        slug = parsed.path.rsplit("/", 1)[-1]
                        return slug
                return text
    return None


def fetch_ticket_category_event_urls(source_url: str, next_data: dict) -> list[str]:
    if not _is_go_out_tickets_url(source_url):
        return []
    payload = _extract_ticket_category_payload(next_data)
    if not payload:
        return []
    endpoint = urljoin(GO_OUT_BASE_URL, GO_OUT_TICKETS_API_PATH)
    headers = {
        "Content-Type": "application/json",
        "Accept": "application/json",
        "Origin": GO_OUT_BASE_URL,
        "Referer": source_url,
        "User-Agent": "Mozilla/5.0",
    }
    try:
        response = requests.post(endpoint, json=payload, headers=headers, timeout=15)
        response.raise_for_status()
    except requests.exceptions.RequestException as exc:
        app.logger.warning(f"Failed to fetch Go-Out tickets events for {source_url}: {exc}")
        return []
    try:
        body = response.json()
    except ValueError:
        return []
    events = body.get("events") if isinstance(body, dict) else None
    if not isinstance(events, list):
        return []
    urls: list[str] = []
    for event in events:
        slug = _extract_event_slug_from_ticket_item(event)
        if not slug:
            continue
        slug = slug.lstrip("/")
        if slug.startswith("event/"):
            slug = slug[len("event/") :]
        if not slug:
            continue
        urls.append(f"{GO_OUT_EVENT_BASE}{slug}")
    return urls


def extract_event_urls_from_page(source_url: str, html: str) -> list[str]:
    try:
        soup = BeautifulSoup(html, "html.parser")
    except Exception:
        return []

    referral = default_referral_code()
    discovered: list[str] = []
    seen: set[str] = set()

    def _dedupe_key(parsed: ParseResult) -> str:
        filtered_qs = [
            (k, v)
            for k, v in parse_qsl(parsed.query, keep_blank_values=True)
            if k.lower() != "ref"
        ]
        query = urlencode(filtered_qs, doseq=True)
        return urlunparse(parsed._replace(query=query, fragment=""))

    def _store(raw_url: str) -> None:
        try:
            normalized = normalize_url(raw_url)
        except Exception:
            return
        parsed = urlparse(normalized)
        if "/event/" not in parsed.path:
            return
        key = _dedupe_key(parsed)
        if key in seen:
            return
        seen.add(key)
        final_url = append_referral_param(normalized, referral)
        discovered.append(final_url or normalized)

    def _build_candidate(value: str | None) -> str | None:
        candidate = (value or "").strip()
        if not candidate:
            return None
        parsed = urlparse(candidate)
        if parsed.scheme and parsed.netloc:
            return candidate
        if candidate.startswith("/"):
            return urljoin(source_url, candidate)
        slug = candidate.lstrip("/")
        if not slug:
            return None
        if slug.startswith("event/"):
            slug = slug[len("event/") :]
        return f"{GO_OUT_EVENT_BASE}{slug}"

    for anchor in soup.find_all("a"):
        href = getattr(anchor, "get", lambda *args, **kwargs: None)("href")
        if not href:
            continue
        absolute = urljoin(source_url, href)
        _store(absolute)
    if discovered:
        return discovered

    script_tag = soup.find("script", {"id": "__NEXT_DATA__"})
    if not script_tag or not getattr(script_tag, "string", None):
        return []
    try:
        data = json.loads(script_tag.string)
    except Exception:
        return []

    for api_url in fetch_ticket_category_event_urls(source_url, data):
        _store(api_url)

    def _collect_from_event_dict(item: dict) -> None:
        for key in ("Url", "url", "slug"):
            if key in item:
                candidate = _build_candidate(item.get(key))
                if candidate:
                    _store(candidate)

    root = data if isinstance(data, dict) else {}
    page_props = root.get("props", {}).get("pageProps", {}) if isinstance(root, dict) else {}
    initial_params = page_props.get("pageInitialParams", {}) if isinstance(page_props, dict) else {}
    for key in ("events", "firstEvents"):
        collection = initial_params.get(key)
        if isinstance(collection, list):
            for item in collection:
                if isinstance(item, dict):
                    _collect_from_event_dict(item)

    ordered: list[str] = []

    def _walk(node):
        if isinstance(node, dict):
            for value in node.values():
                _walk(value)
        elif isinstance(node, list):
            for item in node:
                _walk(item)
        elif isinstance(node, str):
            candidate = _build_candidate(node) if "/event/" not in node else urljoin(source_url, node)
            if candidate:
                _store(candidate)

    _walk(data)
    ordered.extend(discovered)
    return ordered


def ensure_party_for_url(event_url: str, referral: str | None) -> tuple[dict | None, bool]:
    if parties_collection is None:
        return None, False
    canonical = normalize_url(event_url)
    query = {"$or": [{"canonicalUrl": canonical}, {"goOutUrl": canonical}]}
    existing = None
    try:
        existing = parties_collection.find_one(query)
    except Exception as exc:
        app.logger.error(f"Failed to query party for {event_url}: {exc}")
    if existing:
        if referral:
            mutated = dict(existing)
            apply_default_referral(mutated, referral)
            updates = {}
            for key in ("goOutUrl", "originalUrl", "referralCode"):
                if mutated.get(key) != existing.get(key):
                    updates[key] = mutated.get(key)
            if updates:
                try:
                    parties_collection.update_one({"_id": existing.get("_id")}, {"$set": updates})
                    existing.update(updates)
                except Exception as exc:
                    app.logger.warning(
                        f"Failed to update referral for party {existing.get('_id')}: {exc}"
                    )
        return existing, False

    party_data = scrape_party_details(event_url)
    party_data.setdefault("canonicalUrl", canonical)
    if not party_data.get("originalUrl"):
        party_data["originalUrl"] = event_url
    if not party_data.get("goOutUrl"):
        party_data["goOutUrl"] = canonical
    apply_default_referral(party_data, referral)
    party_data.setdefault("slug", slugify_value(party_data.get("name")))
    try:
        result = parties_collection.update_one(query, {"$setOnInsert": party_data}, upsert=True)
    except Exception as exc:
        app.logger.error(f"Failed to upsert party from {event_url}: {exc}")
        raise
    upserted_id = getattr(result, "upserted_id", None)
    if upserted_id is None:
        try:
            existing = parties_collection.find_one(query)
        except Exception as exc:
            app.logger.error(f"Failed to load existing party for {event_url}: {exc}")
            existing = None
        return existing, False

    party_data["_id"] = upserted_id
    event_view = normalize_event(party_data)
    notify_indexers([event_view.get("canonicalUrl")])
    trigger_revalidation(event_related_paths(event_view))
    return party_data, True


def ensure_carousel_contains_party(title: str, party_id) -> tuple[dict | None, bool]:
    if carousels_collection is None:
        return None, False
    carousel_title = (title or "").strip()
    if not carousel_title:
        return None, False

    def _normalize_party_id(value):
        if isinstance(value, ObjectId):
            return value, str(value)
        try:
            oid = ObjectId(value)
            return oid, str(oid)
        except Exception:
            text = str(value)
            return text, text

    storage_id, normalized_id = _normalize_party_id(party_id)

    try:
        existing = carousels_collection.find_one({"title": carousel_title})
    except Exception as exc:
        app.logger.error(f"Failed to query carousel '{carousel_title}': {exc}")
        return None, False

    if existing:
        existing_ids = {str(pid) for pid in existing.get("partyIds", [])}
        if normalized_id in existing_ids:
            return existing, False
        try:
            carousels_collection.update_one({"_id": existing.get("_id")}, {"$push": {"partyIds": storage_id}})
            refreshed = carousels_collection.find_one({"_id": existing.get("_id")}) or existing
            return refreshed, True
        except Exception as exc:
            app.logger.error(
                f"Failed to append party {normalized_id} to carousel '{carousel_title}': {exc}"
            )
            return existing, False

    try:
        last = carousels_collection.find().sort("order", -1).limit(1)
        last_order = next(last, {}).get("order", -1)
    except Exception:
        last_order = -1

    doc = {
        "title": carousel_title,
        "partyIds": [storage_id],
        "order": int(last_order) + 1,
    }
    try:
        result = carousels_collection.insert_one(doc)
        doc["_id"] = getattr(result, "inserted_id", doc.get("_id"))
        return doc, True
    except Exception as exc:
        app.logger.error(f"Failed to create carousel '{carousel_title}': {exc}")
        return None, False


@app.route("/api/admin/carousels", methods=["POST"])
@limiter.limit("10 per minute")
@protect
def add_carousel():
    payload = request.get_json(silent=True) or {}
    try:
        carousel = CarouselCreateSchema(**payload)
    except ValidationError as ve:
        app.logger.warning(f"[VALIDATION] {ve}")
        return jsonify({"message": "Invalid carousel data", "errors": ve.errors()}), 400
    try:
        doc = carousel.dict()
        # assign at end
        last = carousels_collection.find().sort("order", -1).limit(1)
        last_order = next(last, {}).get("order", -1)
        doc["order"] = last_order + 1
        result = carousels_collection.insert_one(doc)
        doc["_id"] = result.inserted_id
        return jsonify(serialize_carousel(doc)), 201
    except Exception as e:
        return jsonify({"message": "Error adding carousel", "error": str(e)}), 500

@app.route("/api/admin/carousels", methods=["GET"])
@limiter.limit("30 per minute")
@protect
def list_admin_carousels():
    try:
        items = [serialize_carousel(doc) for doc in carousels_collection.find().sort("order", 1)]
        return jsonify(items), 200
    except Exception as e:
        return jsonify({"message": "Error fetching carousels", "error": str(e)}), 500


@app.route("/api/admin/carousels/<carousel_id>", methods=["PUT"])
@protect
def update_carousel(carousel_id):
    payload = request.get_json(silent=True) or {}
    try:
        update = CarouselUpdateSchema(**payload)
    except ValidationError as ve:
        app.logger.warning(f"[VALIDATION] {ve}")
        return jsonify({"message": "Invalid carousel data", "errors": ve.errors()}), 400
    update_data = update.dict(exclude_unset=True)
    if not update_data:
        return jsonify({"message": "No valid fields provided."}), 400
    try:
        obj_id = ObjectId(carousel_id)
        result = carousels_collection.update_one({"_id": obj_id}, {"$set": update_data})
        if result.matched_count == 0:
            return jsonify({"message": "Carousel not found"}), 404
        updated_doc = carousels_collection.find_one({"_id": obj_id}) or {}
        return (
            jsonify({"message": "Carousel updated successfully!", "carousel": serialize_carousel(updated_doc)}),
            200,
        )
    except Exception as e:
        return jsonify({"message": "Error updating carousel", "error": str(e)}), 500


@app.route("/api/admin/carousels/<carousel_id>/parties", methods=["GET"])
@limiter.limit("60 per minute")
@protect
def get_carousel_parties(carousel_id):
    try:
        obj_id = ObjectId(carousel_id)
    except Exception:
        return jsonify({"message": "Invalid carousel id."}), 400
    try:
        carousel = carousels_collection.find_one({"_id": obj_id})
        if not carousel:
            return jsonify({"message": "Carousel not found"}), 404
        party_ids = carousel.get("partyIds") or []
        resolved_ids: list[tuple[str, ObjectId]] = []
        for pid in party_ids:
            try:
                resolved_ids.append((str(pid), ObjectId(pid)))
            except Exception:
                return jsonify({"message": "Carousel contains invalid party identifiers."}), 400
        if not resolved_ids:
            return jsonify([]), 200
        lookup_ids = [oid for _, oid in resolved_ids]
        parties = list(parties_collection.find({"_id": {"$in": lookup_ids}}))
        parties_by_id = {str(doc.get("_id")): doc for doc in parties}
        items = []
        for original_id, oid in resolved_ids:
            doc = parties_by_id.get(str(oid))
            if not doc:
                continue
            payload = dict(doc)
            payload["_id"] = str(payload.get("_id"))
            items.append(payload)
        return jsonify(items), 200
    except Exception as e:
        return jsonify({"message": "Error fetching carousel parties", "error": str(e)}), 500


@app.route("/api/admin/carousels/<carousel_id>/parties", methods=["PUT"])
@protect
def update_carousel_parties(carousel_id):
    payload = request.get_json(silent=True) or {}
    try:
        update = CarouselPartiesUpdateSchema(**payload)
    except ValidationError as ve:
        app.logger.warning(f"[VALIDATION] {ve}")
        return jsonify({"message": "Invalid carousel data", "errors": ve.errors()}), 400
    normalized_ids: list[str] = []
    lookup_ids: list[ObjectId] = []
    for pid in update.partyIds:
        try:
            oid = ObjectId(pid)
        except Exception:
            return jsonify({"message": "partyIds must contain valid identifiers."}), 400
        normalized_ids.append(str(oid))
        lookup_ids.append(oid)
    try:
        obj_id = ObjectId(carousel_id)
    except Exception:
        return jsonify({"message": "Invalid carousel id."}), 400
    try:
        if lookup_ids:
            existing_ids = {str(doc.get("_id")) for doc in parties_collection.find({"_id": {"$in": lookup_ids}}, {"_id": 1})}
            missing = [pid for pid in normalized_ids if pid not in existing_ids]
            if missing:
                return jsonify({"message": "Some parties do not exist.", "missing": missing}), 400
        result = carousels_collection.update_one({"_id": obj_id}, {"$set": {"partyIds": normalized_ids}})
        if result.matched_count == 0:
            return jsonify({"message": "Carousel not found"}), 404
        updated_doc = carousels_collection.find_one({"_id": obj_id}) or {}
        return (
            jsonify({"message": "Carousel parties updated successfully!", "carousel": serialize_carousel(updated_doc)}),
            200,
        )
    except Exception as e:
        return jsonify({"message": "Error updating carousel parties", "error": str(e)}), 500


@app.route("/api/admin/carousels/<carousel_id>", methods=["DELETE"])
@protect
def delete_carousel(carousel_id):
    try:
        obj_id = ObjectId(carousel_id)
        result = carousels_collection.delete_one({"_id": obj_id})
        if result.deleted_count == 0:
            return jsonify({"message": "Carousel not found."}), 404
        return jsonify({"message": "Carousel deleted successfully!"}), 200
    except Exception as e:
        return jsonify({"message": "Error deleting carousel", "error": str(e)}), 500

@app.route("/api/carousels", methods=["GET"])
@limiter.limit("100 per minute")
def get_carousels():
    try:
        items = [serialize_carousel(carousel) for carousel in carousels_collection.find().sort("order", 1)]
        return jsonify(items), 200
    except Exception as e:
        return jsonify({"message": "Error fetching carousels", "error": str(e)}), 500

@app.route("/api/admin/carousels/reorder", methods=["POST"])
@protect
def reorder_carousels():
    payload = request.get_json(silent=True) or {}
    try:
        req = CarouselReorderSchema(**payload)
    except ValidationError as ve:
        return jsonify({"message": "Invalid payload", "errors": ve.errors()}), 400
    ids = []
    try:
        ids = [ObjectId(i) for i in req.orderedIds]
    except Exception:
        return jsonify({"message": "orderedIds must be valid ObjectIds"}), 400
    existing = list(carousels_collection.find({"_id": {"$in": ids}}, {"_id": 1}))
    if len(existing) != len(ids):
        return jsonify({"message": "Some carousel IDs do not exist."}), 400
    ids = [ObjectId(i) for i in req.orderedIds]
    ops = [UpdateOne({"_id": oid}, {"$set": {"order": idx}}) for idx, oid in enumerate(ids)]
    if not ops:
        return jsonify({"message": "No items to reorder"}), 400
    try:
        carousels_collection.bulk_write(ops, ordered=True)
        return jsonify({"message": "Reordered"}), 200
    except Exception as e:
        return jsonify({"message": "Error reordering carousels", "error": str(e)}), 500
# --- Tags APIs ---
@app.route("/api/tags", methods=["GET"])
@limiter.limit("100 per minute")
def list_tags():
    try:
        ensure_tags_seeded()
        docs = list(tags_collection.find().sort([("order", 1), ("name", 1)]))
        items = [{"slug": d["slug"], "name": d.get("name", d["slug"]), "order": d.get("order", 0)} for d in docs]
        return jsonify(items), 200
    except Exception as e:
        return jsonify({"message": "Error fetching tags", "error": str(e)}), 500

@app.route("/api/admin/tags/order", methods=["POST"])
@limiter.limit("100 per minute")
@protect
def reorder_tag():
    payload = request.get_json(silent=True) or {}
    try:
        req = TagOrderRequest(**payload)
    except ValidationError as ve:
        return jsonify({"message": "Invalid payload", "errors": ve.errors()}), 400
    ensure_tags_seeded()
    docs = list(tags_collection.find().sort([("order", 1), ("name", 1)]))
    slugs = [d["slug"] for d in docs]
    if req.slug not in slugs:
        return jsonify({"message": "Tag not found"}), 404
    old_index = slugs.index(req.slug)
    new_index = max(0, min(req.newIndex, len(slugs) - 1))
    if new_index == old_index:
        return jsonify({"message": "No change"}), 200
    # reorder list
    item = docs.pop(old_index)
    docs.insert(new_index, item)
    # write back sequential order
    ops = []
    for idx, d in enumerate(docs):
        ops.append(tags_collection.update_one({"_id": d["_id"]}, {"$set": {"order": idx}}))
    try:
        tags_collection.bulk_write(ops)
        return jsonify({"message": "Tag order updated"}), 200
    except Exception as e:
        return jsonify({"message": "Error updating tag order", "error": str(e)}), 500

@app.route("/api/admin/tags/rename", methods=["POST"])
@limiter.limit("100 per minute")
@protect
def rename_tag():
    payload = request.get_json(silent=True) or {}
    tag_id_raw = (payload.get("tagId") or "").strip()
    new_name = (payload.get("newName") or "").strip()
    if not tag_id_raw or not new_name:
        return jsonify({"message": "tagId and newName are required"}), 400

    try:
        tag_id = ObjectId(tag_id_raw)
    except Exception as exc:
        return jsonify({"message": "Invalid tagId", "error": str(exc)}), 400

    tag_doc = tags_collection.find_one({"_id": tag_id})
    if not tag_doc:
        return jsonify({"message": "Tag not found"}), 404

    new_slug = slugify_tag(new_name)
    existing = tags_collection.find_one({"slug": new_slug})
    if existing and existing.get("_id") != tag_doc.get("_id"):
        return jsonify({"message": "A tag with that name already exists"}), 409

    old_name = tag_doc.get("name", "")
    try:
        tags_collection.update_one(
            {"_id": tag_doc["_id"]},
            {"$set": {"name": new_name, "slug": new_slug}},
        )
        if old_name:
            parties_collection.update_many(
                {"tags": old_name},
                {"$set": {"tags.$[elem]": new_name}},
                array_filters=[{"elem": old_name}],
            )
        return jsonify({"message": "Tag renamed"}), 200
    except Exception as exc:
        return jsonify({"message": "Error renaming tag", "error": str(exc)}), 500


@app.route("/api/admin/carousel/rename", methods=["POST"])
@limiter.limit("100 per minute")
@protect
def rename_carousel():
    payload = request.get_json(silent=True) or {}
    carousel_id = (payload.get("carouselId") or "").strip()
    new_title = (payload.get("newName") or "").strip()
    if not carousel_id or not new_title:
        return jsonify({"message": "carouselId and newName are required"}), 400

    try:
        obj_id = ObjectId(carousel_id)
    except Exception as e:
        return jsonify({"message": "Invalid carouselId", "error": str(e)}), 400

    carousel = carousels_collection.find_one({"_id": obj_id})
    if not carousel:
        return jsonify({"message": "Carousel not found"}), 404

    old_title = carousel.get("title", "")
    if old_title == new_title:
        return jsonify({"message": "No change"}), 200

    existing = carousels_collection.find_one({"title": new_title})
    if existing and existing["_id"] != carousel["_id"]:
        return jsonify({"message": "A carousel with the new title already exists"}), 409

    try:
        carousels_collection.update_one(
            {"_id": carousel["_id"]},
            {"$set": {"title": new_title}}
        )
        return jsonify({"message": "Carousel renamed"}), 200
    except Exception as e:
        return jsonify({"message": "Error renaming carousel", "error": str(e)}), 500


def normalize_section_doc(doc: dict | None) -> dict:
    data = dict(doc or {})
    if "_id" in data and data["_id"] is not None:
        data["_id"] = str(data["_id"])
    return data


def _coerce_section_id(value):
    try:
        return ObjectId(value)
    except Exception:
        return value


@app.route("/api/admin/sections/<section_id>", methods=["PUT"])
@protect
def update_section(section_id):
    if sections_collection is None:
        return jsonify({"message": "Storage unavailable."}), 503
    payload = request.get_json(silent=True) or {}
    try:
        req = SectionUpdateSchema(**payload)
    except ValidationError as ve:
        app.logger.warning(f"[VALIDATION] {ve}")
        return jsonify({"message": "Invalid payload", "errors": ve.errors()}), 400
    updates = {}
    if req.title is not None:
        updates["title"] = (req.title or "").strip()
    if req.content is not None:
        updates["content"] = req.content
    if req.slug is not None:
        slug = slugify_value(req.slug)
        if not slug:
            return jsonify({"message": "Unable to derive slug from provided data."}), 400
        updates["slug"] = slug
    if not updates:
        return jsonify({"message": "No valid fields provided."}), 400
    updates["updatedAt"] = isoformat_or_none(datetime.utcnow().replace(tzinfo=timezone.utc))
    identifier = _coerce_section_id(section_id)
    try:
        result = sections_collection.update_one({"_id": identifier}, {"$set": updates})
    except Exception as exc:
        return jsonify({"message": "Error updating section", "error": str(exc)}), 500
    if getattr(result, "matched_count", 0) == 0:
        return jsonify({"message": "Section not found"}), 404
    try:
        updated_doc = sections_collection.find_one({"_id": identifier})
    except Exception as exc:
        return jsonify({"message": "Error loading section", "error": str(exc)}), 500
    return (
        jsonify({"message": "Section updated successfully!", "section": normalize_section_doc(updated_doc)}),
        200,
    )


@app.route("/api/admin/sections/reorder", methods=["POST"])
@protect
def reorder_sections():
    if sections_collection is None:
        return jsonify({"message": "Storage unavailable."}), 503
    payload = request.get_json(silent=True) or {}
    try:
        req = SectionReorderSchema(**payload)
    except ValidationError as ve:
        app.logger.warning(f"[VALIDATION] {ve}")
        return jsonify({"message": "Invalid payload", "errors": ve.errors()}), 400
    if not req.orderedIds:
        return jsonify({"message": "No items to reorder"}), 400
    missing: list[str] = []
    for idx, raw_id in enumerate(req.orderedIds):
        identifier = _coerce_section_id(raw_id)
        try:
            result = sections_collection.update_one({"_id": identifier}, {"$set": {"order": idx}})
        except Exception as exc:
            return jsonify({"message": "Error reordering sections", "error": str(exc)}), 500
        if getattr(result, "matched_count", 0) == 0:
            missing.append(str(raw_id))
    if missing:
        return jsonify({"message": "Some sections were not found.", "missing": missing}), 404
    return jsonify({"message": "Sections reordered"}), 200


@app.route("/api/sections", methods=["GET"])
def list_sections():
    if sections_collection is None:
        return jsonify([]), 200
    try:
        cursor = sections_collection.find().sort("order", 1)
    except AttributeError:
        cursor = sections_collection.find()
    except Exception as exc:
        return jsonify({"message": "Error fetching sections", "error": str(exc)}), 500
    items = [normalize_section_doc(doc) for doc in cursor]
    return jsonify(items), 200


def add_parties_to_carousel_from_urls(
    title: str, event_urls: Iterable[str], referral: str | None
) -> tuple[dict | None, int, list[dict]]:
    collected: list[dict] = []
    warnings: list[dict] = []

    for event_url in event_urls:
        try:
            party_doc, _created = ensure_party_for_url(event_url, referral)
        except Exception as exc:
            warnings.append({"url": event_url, "error": str(exc)})
            continue
        if not party_doc or not party_doc.get("_id"):
            warnings.append({"url": event_url, "error": "Missing party identifier"})
            continue
        collected.append(party_doc)

    carousel_doc = None
    added_count = 0
    for doc in collected:
        raw_id = doc.get("_id")
        if raw_id is None:
            continue
        carousel_doc, added = ensure_carousel_contains_party(title, raw_id)
        if added:
            added_count += 1

    return carousel_doc, added_count, warnings


def _import_carousel_from_urls(carousel_name: str, urls: list[str], referral: str | None):
    if not urls:
        return None, 0, []
    return add_parties_to_carousel_from_urls(carousel_name, urls, referral)


@app.route("/api/admin/import/carousel-urls", methods=["POST"])
@limiter.limit("5 per minute")
@protect
def import_carousel_from_urls():
    payload = request.get_json(silent=True) or {}
    try:
        req = CarouselUrlListImportSchema(**payload)
    except ValidationError as ve:
        app.logger.warning(f"[VALIDATION] {ve}")
        return jsonify({"message": "Invalid payload", "errors": ve.errors()}), 400

    carousel_name = (req.carouselName or "").strip()
    if not carousel_name:
        return jsonify({"message": "carouselName is required"}), 400

    cleaned_urls: list[str] = []
    for raw in req.urls:
        url = (raw or "").strip()
        if not url or not is_url_allowed(url):
            return jsonify({"message": "All URLs must be valid and publicly reachable."}), 400
        cleaned_urls.append(url)

    if not cleaned_urls:
        return jsonify({"message": "At least one URL is required."}), 400

    referral = (req.referral or "").strip() or default_referral_code()

    carousel_doc, added_count, warnings = _import_carousel_from_urls(
        carousel_name, cleaned_urls, referral
    )

    if carousel_doc is None:
        return (
            jsonify({"message": "Unable to update carousel from provided URLs."}),
            404,
        )

    response_payload = {
        "message": "Carousel updated from URLs.",
        "carousel": serialize_carousel(carousel_doc),
        "addedCount": added_count,
        "processedUrlCount": len(cleaned_urls),
    }
    if warnings:
        response_payload["warnings"] = warnings

    return jsonify(response_payload), 200


@app.route("/api/admin/sections", methods=["POST"])
@limiter.limit("5 per minute")
@protect
def add_section():
    payload = request.get_json(silent=True) or {}
    if sections_collection is None:
        return jsonify({"message": "Storage unavailable."}), 503
    try:
        section_req = SectionCreateSchema(**payload)
    except ValidationError as ve:
        app.logger.warning(f"[VALIDATION] {ve}")
        return jsonify({"message": "Invalid payload", "errors": ve.errors()}), 400
    title = (section_req.title or "").strip()
    content = section_req.content
    if not title:
        return jsonify({"message": "title is required"}), 400
    slug_source = section_req.slug or title
    slug = slugify_value(slug_source)
    if not slug:
        return jsonify({"message": "Unable to derive slug from provided data."}), 400
    try:
        last = sections_collection.find().sort("order", -1).limit(1)
        last_order = next(last, {}).get("order", -1)
    except Exception:
        last_order = -1
    now = isoformat_or_none(datetime.utcnow().replace(tzinfo=timezone.utc))
    doc = {
        "title": title,
        "content": content,
        "slug": slug,
        "order": int(last_order) + 1,
        "createdAt": now,
        "updatedAt": now,
    }
    try:
        result = sections_collection.insert_one(doc)
        doc["_id"] = getattr(result, "inserted_id", doc.get("_id"))
    except Exception as exc:
        return jsonify({"message": "Error creating section", "error": str(exc)}), 500
    payload = dict(doc)
    if payload.get("_id") is not None:
        payload["_id"] = str(payload["_id"])
    return jsonify(payload), 201


# --- Discovery surfaces ---


def sitemap_xml(entries: list[dict], root_tag: str = "urlset") -> str:
    item_tag = "sitemap" if root_tag == "sitemapindex" else "url"
    body = [f"<{root_tag} xmlns=\"http://www.sitemaps.org/schemas/sitemap/0.9\">"]
    for entry in entries:
        loc = entry.get("loc")
        lastmod = entry.get("lastmod")
        if not loc:
            continue
        body.append(f"<{item_tag}><loc>{loc}</loc>{'<lastmod>'+lastmod+'</lastmod>' if lastmod else ''}</{item_tag}>")
    body.append(f"</{root_tag}>")
    return "".join(body)


@app.route("/sitemap.xml")
def sitemap_index():
    upcoming = serialize_events(include_past=False)
    shards = shard_events(upcoming)
    entries = []
    for idx, shard in enumerate(shards):
        lastmod = None
        for event in shard:
            if event.get("lastmod") and (not lastmod or event["lastmod"] > lastmod):
                lastmod = event["lastmod"]
        name = f"events-{idx}.xml"
        entries.append({
            "loc": build_canonical("sitemap_child", name=name),
            "lastmod": lastmod,
        })
    for name, getter in (
        ("cities.xml", lambda: aggregate_dimension(upcoming, "city")),
        ("venues.xml", lambda: aggregate_dimension(upcoming, "venue")),
        ("genres.xml", lambda: aggregate_genres(upcoming)),
        ("dates.xml", lambda: unique_dates(upcoming)),
    ):
        items = getter()
        lastmod = None
        for item in items:
            if item.get("lastmod") and (not lastmod or item["lastmod"] > lastmod):
                lastmod = item["lastmod"]
        entries.append({
            "loc": build_canonical("sitemap_child", name=name),
            "lastmod": lastmod,
        })
    record_setting_hit("analytics:sitemap:index")
    xml = sitemap_xml(entries, root_tag="sitemapindex")
    return text_response(xml, "application/xml", cache_seconds=SITEMAP_CACHE_SECONDS, robots=None)


def sitemap_child_response(items: list[dict]):
    entries = []
    for item in items:
        loc = item.get("canonicalUrl") or item.get("loc")
        if not loc:
            continue
        entries.append({"loc": loc, "lastmod": item.get("lastmod")})
    xml = sitemap_xml(entries)
    return text_response(xml, "application/xml", cache_seconds=SITEMAP_CACHE_SECONDS, robots=None)


@app.route("/sitemaps/events-<int:shard>.xml")
def sitemap_events_shard(shard: int):
    upcoming = serialize_events(include_past=False)
    shards = shard_events(upcoming)
    if shard < 0 or shard >= len(shards):
        return text_response("", "application/xml", cache_seconds=SITEMAP_CACHE_SECONDS, robots=None, status=404)
    events = shards[shard]
    items = [{"canonicalUrl": event.get("canonicalUrl"), "lastmod": event.get("lastmod") } for event in events]
    record_setting_hit("analytics:sitemap:events", {"shard": shard})
    return sitemap_child_response(items)


@app.route("/sitemaps/cities.xml")
def sitemap_cities():
    upcoming = serialize_events(include_past=False)
    items = aggregate_dimension(upcoming, "city")
    record_setting_hit("analytics:sitemap:cities")
    return sitemap_child_response(items)


@app.route("/sitemaps/venues.xml")
def sitemap_venues():
    upcoming = serialize_events(include_past=False)
    items = aggregate_dimension(upcoming, "venue")
    record_setting_hit("analytics:sitemap:venues")
    return sitemap_child_response(items)


@app.route("/sitemaps/genres.xml")
def sitemap_genres():
    upcoming = serialize_events(include_past=False)
    items = aggregate_genres(upcoming)
    record_setting_hit("analytics:sitemap:genres")
    return sitemap_child_response(items)


@app.route("/sitemaps/dates.xml")
def sitemap_dates():
    upcoming = serialize_events(include_past=False)
    items = unique_dates(upcoming)
    record_setting_hit("analytics:sitemap:dates")
    return sitemap_child_response(items)


def filtered_events_for_scope(scope_slug: str | None) -> tuple[list[dict], str, str]:
    events = serialize_events(include_past=False)
    scope_title = "Parties247 Events"
    scope_url = build_canonical("events_feed", fmt="rss").rsplit(".", 1)[0]
    if scope_slug:
        cities = {item["slug"]: item for item in aggregate_dimension(events, "city")}
        genres = {item["slug"]: item for item in aggregate_genres(events)}
        matched = []
        if scope_slug in cities:
            matched = [event for event in events if event.get("city", {}).get("slug") == scope_slug]
            scope_title = f"Events in {cities[scope_slug]['name']['en'] or cities[scope_slug]['name']['he']}"
            scope_url = build_canonical("scoped_feed", slug=scope_slug, fmt="rss").rsplit(".", 1)[0]
        elif scope_slug in genres:
            matched = [event for event in events if any(g.get("slug") == scope_slug for g in event.get("genres", []))]
            scope_title = f"{genres[scope_slug]['name']['en'] or genres[scope_slug]['name']['he']} Events"
            scope_url = build_canonical("scoped_feed", slug=scope_slug, fmt="rss").rsplit(".", 1)[0]
        events = matched
    return events, scope_title, scope_url


def feed_response(scope_slug: str | None, fmt: str):
    fmt = fmt.lower()
    events, title, url = filtered_events_for_scope(scope_slug)
    if scope_slug and not events:
        return text_response("", "text/plain", cache_seconds=FEED_CACHE_SECONDS, robots="noindex", status=404)
    body = build_feed(events, title, url, fmt)
    content_type = {
        "rss": "application/rss+xml",
        "atom": "application/atom+xml",
        "json": "application/feed+json",
    }.get(fmt, "application/octet-stream")
    record_setting_hit("analytics:feed", {"scope": scope_slug or "events", "format": fmt})
    return text_response(body, content_type, cache_seconds=FEED_CACHE_SECONDS, robots="noindex")


@app.route("/feeds/events.<fmt>")
def feeds_events(fmt: str):
    return feed_response(None, fmt)


@app.route("/feeds/<slug>.<fmt>")
def feeds_scope(slug: str, fmt: str):
    return feed_response(slug, fmt)


@app.route("/ics/event/<slug>.ics")
def ics_event(slug: str):
    events = [event for event in serialize_events(include_past=True) if event.get("slug") == slug]
    if not events:
        return text_response("", "text/calendar", cache_seconds=ICS_CACHE_SECONDS, robots="noindex", status=404)
    body = build_ics(events, title=events[0].get("title", {}).get("en") or events[0].get("title", {}).get("he") or "Event")
    record_setting_hit("analytics:ics:event", {"slug": slug})
    return text_response(body, "text/calendar", cache_seconds=ICS_CACHE_SECONDS, robots="noindex")


@app.route("/ics/city/<slug>.ics")
def ics_city(slug: str):
    events = [event for event in serialize_events(include_past=False) if event.get("city", {}).get("slug") == slug]
    if not events:
        return text_response("", "text/calendar", cache_seconds=ICS_CACHE_SECONDS, robots="noindex", status=404)
    title = f"Events in {events[0].get('city', {}).get('name', {}).get('en') or events[0].get('city', {}).get('name', {}).get('he') or slug}"
    body = build_ics(events, title=title)
    record_setting_hit("analytics:ics:city", {"slug": slug})
    return text_response(body, "text/calendar", cache_seconds=ICS_CACHE_SECONDS, robots="noindex")


@app.route("/robots.txt")
def robots_txt():
    lines = [
        "User-agent: *",
        "Disallow: /api/",
        "Disallow: /feeds/",
        "Disallow: /search",
        "Disallow: /admin",
        f"Sitemap: {build_canonical('sitemap_index')}",
    ]
    return text_response("\n".join(lines) + "\n", "text/plain", cache_seconds=LIST_CACHE_SECONDS, robots=None)

@app.route("/api/referral", methods=["GET"])
def get_referral():
    try:
        code = default_referral_code() or ""
        return jsonify({"referral": code}), 200
    except Exception as e:
        return jsonify({"message": "Error fetching referral", "error": str(e)}), 500

@app.route("/api/admin/referral", methods=["POST"])
@protect
def set_referral():
    payload = request.get_json(silent=True) or {}
    try:
        req = ReferralUpdateSchema(**payload)
    except ValidationError as ve:
        return jsonify({"message": "Invalid payload", "errors": ve.errors()}), 400
    val = (req.code or "").strip()
    if not re.fullmatch(r"[A-Za-z0-9_-]{1,64}", val):
        return jsonify({"message": "Invalid referral format. Use 1-64 chars [A-Za-z0-9_-]."}), 400
    try:
        settings_collection.update_one(
            {"key": REFERRAL_KEY},
            {"$set": {"key": REFERRAL_KEY, "value": val}},
            upsert=True
        )
        return jsonify({"message": "Referral updated"}), 200
    except Exception as e:
        return jsonify({"message": "Error updating referral", "error": str(e)}), 500

# --- Advanced Classification Helpers ---

def classify_party_data(title: str, description: str, location: str) -> dict:
    """
    Analyzes text to extract Audience, Genre, and Area based on specific keywords.
    Returns a dict with lists for 'audiences', 'musicGenres', 'areas'.
    """
    # Combine text for analysis
    full_text = f"{title or ''} {description or ''} {location or ''}".lower()
    loc_text = (location or "").lower()

    # 1. Audience Analysis
    audiences = set()
    
    # Age Keywords
    if "18+" in full_text or "18 +" in full_text or "18 plus" in full_text:
        audiences.add("18+")
    if "24+" in full_text or "24 +" in full_text or "24 plus" in full_text:
        audiences.add("24+")
    if "30+" in full_text or "30 +" in full_text or "30 plus" in full_text:
        audiences.add("30+")
    
    # Specific Groups
    if any(w in full_text for w in ["student", ""]):
        audiences.add("students")
    if any(w in full_text for w in ["soldier", "", "", "uniform"]):
        audiences.add("soldiers")
    if any(w in full_text for w in ["noar", "", "16+", "17+"]):
        audiences.add("youth")
        
    # If explicit older ages are found, it often implies 18+ as well, 
    # but we will stick to explicit tags found to allow precise filtering.

    # 2. Genre Analysis
    genres = set()
    if any(w in full_text for w in ["techno", "", "melodic", "after"]):
        genres.add("techno")
    if any(w in full_text for w in ["house", "", "deep"]):
        genres.add("house")
    if any(w in full_text for w in ["trance", "", "psy", "", "goa"]):
        genres.add("trance")
    if any(w in full_text for w in ["hip hop", "hiphop", " ", "rap", "", "black", ""]):
        genres.add("hiphop")
    if any(w in full_text for w in ["mainstream", "", "pop", "", "reggaeton", "", "hits"]):
        genres.add("mainstream")

    # 3. Area Analysis
    areas = set()
    
    # Tel Aviv
    if any(w in full_text for w in ["tel aviv", "tlv", " ", "", "center"]):
        areas.add("tel aviv")
    
    # Haifa (Specific check before general North)
    if any(w in full_text for w in ["haifa", "", "krayot", ""]):
        areas.add("haifa")
    
    # Eilat
    if any(w in full_text for w in ["eilat", ""]):
        areas.add("eilat")
    
    # North (General)
    if "haifa" not in areas and any(w in full_text for w in ["north", "", "tiberias", "kinneret", "galil"]):
        areas.add("north")
    elif "haifa" in areas: 
        # Optional: You can decide if Haifa also counts as North. 
        # For now, we keep them distinct as per your request list, or add both:
        areas.add("north") 

    # South (General)
    if "eilat" not in areas and any(w in full_text for w in ["south", "", "beer sheva", "b7", "ashdod", "ashkelon"]):
        areas.add("south")
    elif "eilat" in areas:
        areas.add("south")

    return {
        "audiences": list(audiences),
        "musicGenres": list(genres),
        "areas": list(areas)
    }

# --- Token verify ---
@app.route('/api/admin/verify-token', methods=['POST'])
@limiter.limit("10 per minute")
@protect
def verify_token():
    return jsonify({"message": "Token is valid."}), 200

if __name__ == "__main__":
    flask_env = os.environ.get("FLASK_ENV", "production").lower()
    debug = flask_env == "development" or (
        flask_env != "production"
        and os.environ.get("DEBUG", "").lower() in ("1", "true", "yes")
    )
    app.run(debug=debug, port=int(os.environ.get("PORT", 3001)))